"""
SCRIPT D'INF√âRENCE - CatBoost
Pr√©dit les d√©cisions (Validation Auto / Rejet Auto / Audit Humain) sur une nouvelle base de donn√©es
Usage: python inference.py --input_file chemin/vers/nouvelle_base.xlsx
"""
import sys
sys.path.append('src')

import pandas as pd
import numpy as np
import joblib
from pathlib import Path
import argparse
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# Import du preprocessing
from data_preprocessing import DataPreprocessor


def load_model_and_preprocessor():
    """Charger le mod√®le CatBoost et le preprocessor"""
    print("\n" + "="*80)
    print("üìÇ CHARGEMENT DU MOD√àLE ET PREPROCESSOR")
    print("="*80)

    # Chemins
    model_path = Path('outputs/production/models/catboost_model.pkl')
    preprocessor_path = Path('outputs/production/models/preprocessor.pkl')
    predictions_path = Path('outputs/production/predictions/predictions_2025.pkl')

    # V√©rifier que les fichiers existent
    if not model_path.exists():
        print(f"‚ùå Mod√®le non trouv√©: {model_path}")
        print("   Ex√©cutez d'abord: python model_comparison.py")
        return None, None, None, None

    if not preprocessor_path.exists():
        print(f"‚ùå Preprocessor non trouv√©: {preprocessor_path}")
        print("   Ex√©cutez d'abord: python model_comparison.py")
        return None, None, None, None

    # Charger le mod√®le
    model = joblib.load(model_path)
    print(f"‚úÖ Mod√®le CatBoost charg√© depuis: {model_path}")

    # Charger le preprocessor
    preprocessor = joblib.load(preprocessor_path)
    print(f"‚úÖ Preprocessor charg√© depuis: {preprocessor_path}")

    # Charger les seuils depuis les pr√©dictions
    if predictions_path.exists():
        predictions_data = joblib.load(predictions_path)
        if 'CatBoost' in predictions_data:
            threshold_low = predictions_data['CatBoost']['threshold_low']
            threshold_high = predictions_data['CatBoost']['threshold_high']
            print(f"‚úÖ Seuils charg√©s: {threshold_low:.4f} / {threshold_high:.4f}")
        else:
            print("‚ö†Ô∏è  Seuils non trouv√©s, utilisation de valeurs par d√©faut")
            threshold_low = 0.3
            threshold_high = 0.7
    else:
        print("‚ö†Ô∏è  Fichier de pr√©dictions non trouv√©, utilisation de seuils par d√©faut")
        threshold_low = 0.3
        threshold_high = 0.7

    return model, preprocessor, threshold_low, threshold_high


def load_new_data(file_path):
    """Charger la nouvelle base de donn√©es"""
    print("\n" + "="*80)
    print("üìÇ CHARGEMENT DES NOUVELLES DONN√âES")
    print("="*80)

    if not Path(file_path).exists():
        print(f"‚ùå Fichier non trouv√©: {file_path}")
        return None

    # Charger les donn√©es
    df = pd.read_excel(file_path)
    print(f"‚úÖ Donn√©es charg√©es: {len(df)} r√©clamations")
    print(f"   Colonnes: {len(df.columns)}")

    return df


def verify_required_columns(df, preprocessor):
    """V√©rifier que toutes les colonnes n√©cessaires sont pr√©sentes"""
    print("\n" + "="*80)
    print("üîç V√âRIFICATION DES COLONNES")
    print("="*80)

    # Colonnes de base n√©cessaires
    required_base_cols = [
        'Date de Qualification',
        'Montant demand√©',
        'Famille Produit'
    ]

    # V√©rifier les colonnes de base
    missing_cols = []
    for col in required_base_cols:
        if col not in df.columns:
            missing_cols.append(col)

    if missing_cols:
        print(f"‚ùå Colonnes manquantes: {missing_cols}")
        print("\nColonnes disponibles:")
        for col in df.columns:
            print(f"  - {col}")
        return False

    print(f"‚úÖ Toutes les colonnes de base sont pr√©sentes")

    # Afficher les colonnes disponibles
    print(f"\nüìã Colonnes d√©tect√©es ({len(df.columns)}):")
    for col in df.columns:
        print(f"  - {col}")

    return True


def preprocess_data(df, preprocessor):
    """Appliquer le preprocessing sur les nouvelles donn√©es"""
    print("\n" + "="*80)
    print("‚öôÔ∏è  PREPROCESSING DES DONN√âES")
    print("="*80)

    try:
        # Le preprocessor applique automatiquement toutes les transformations
        X_processed = preprocessor.transform(df)
        print(f"‚úÖ Preprocessing r√©ussi")
        print(f"   Shape apr√®s preprocessing: {X_processed.shape}")

        return X_processed

    except Exception as e:
        print(f"‚ùå Erreur lors du preprocessing: {str(e)}")
        return None


def make_predictions(model, X_processed, threshold_low, threshold_high):
    """Faire les pr√©dictions avec le mod√®le"""
    print("\n" + "="*80)
    print("ü§ñ PR√âDICTION DU MOD√àLE")
    print("="*80)

    # Pr√©dire les probabilit√©s
    y_prob = model.predict_proba(X_processed)[:, 1]
    print(f"‚úÖ Pr√©dictions calcul√©es pour {len(y_prob)} r√©clamations")

    # Appliquer les seuils pour obtenir les 3 d√©cisions
    decisions = []
    decisions_code = []

    for prob in y_prob:
        if prob <= threshold_low:
            decisions.append('Rejet Auto')
            decisions_code.append(0)
        elif prob >= threshold_high:
            decisions.append('Validation Auto')
            decisions_code.append(1)
        else:
            decisions.append('Audit Humain')
            decisions_code.append(-1)

    # Statistiques
    n_rejet = decisions_code.count(0)
    n_audit = decisions_code.count(-1)
    n_validation = decisions_code.count(1)
    total = len(decisions_code)

    print(f"\nüìä R√©partition des d√©cisions:")
    print(f"   Rejet Auto       : {n_rejet:6d} ({100*n_rejet/total:5.1f}%)")
    print(f"   Audit Humain     : {n_audit:6d} ({100*n_audit/total:5.1f}%)")
    print(f"   Validation Auto  : {n_validation:6d} ({100*n_validation/total:5.1f}%)")
    print(f"   TOTAL            : {total:6d}")

    print(f"\nüìà Statistiques des probabilit√©s:")
    print(f"   Min  : {y_prob.min():.4f}")
    print(f"   Max  : {y_prob.max():.4f}")
    print(f"   Mean : {y_prob.mean():.4f}")
    print(f"   Median: {np.median(y_prob):.4f}")

    return y_prob, decisions, decisions_code


def apply_business_rule(df_results):
    """Appliquer la r√®gle m√©tier: 1 validation auto par client par ann√©e"""
    print("\n" + "="*80)
    print("üîí APPLICATION DE LA R√àGLE M√âTIER")
    print("="*80)
    print("R√®gle: 1 validation automatique par client par ann√©e")

    df_scenario = df_results.copy()

    # Convertir la date
    df_scenario['Date de Qualification'] = pd.to_datetime(
        df_scenario['Date de Qualification'],
        errors='coerce'
    )
    df_scenario['Annee'] = df_scenario['Date de Qualification'].dt.year

    # Identifier la colonne client
    client_col = None
    for col in ['idtfcl', 'numero_compte', 'N compte', 'ID Client']:
        if col in df_scenario.columns:
            client_col = col
            break

    if client_col is None:
        print("‚ö†Ô∏è  Aucune colonne client trouv√©e, r√®gle m√©tier non appliqu√©e")
        df_scenario['D√©cision_Finale'] = df_scenario['D√©cision_Mod√®le']
        return df_scenario

    print(f"‚úÖ Colonne client identifi√©e: {client_col}")

    # Trier par client, ann√©e, puis date
    df_scenario = df_scenario.sort_values([client_col, 'Annee', 'Date de Qualification'])

    # Marquer les validations automatiques
    df_scenario['is_validation_auto'] = (df_scenario['D√©cision_Code'] == 1)

    # Compter les validations auto par client/ann√©e
    df_scenario['validation_rank'] = df_scenario.groupby([client_col, 'Annee'])['is_validation_auto'].cumsum()

    # Appliquer la r√®gle: seule la premi√®re validation auto est accept√©e
    df_scenario['D√©cision_Finale'] = df_scenario['D√©cision_Mod√®le'].copy()
    mask_blocked = (df_scenario['is_validation_auto']) & (df_scenario['validation_rank'] > 1)
    df_scenario.loc[mask_blocked, 'D√©cision_Finale'] = 'Audit Humain (R√®gle)'

    # Statistiques
    n_blocked = mask_blocked.sum()
    if n_blocked > 0:
        print(f"\nüìä Impact de la r√®gle m√©tier:")
        print(f"   Validations bloqu√©es : {n_blocked}")
        print(f"   Ces r√©clamations sont maintenant en 'Audit Humain (R√®gle)'")
    else:
        print(f"\n‚úÖ Aucune validation bloqu√©e par la r√®gle m√©tier")

    return df_scenario


def save_results(df_results, output_path):
    """Sauvegarder les r√©sultats dans un fichier Excel"""
    print("\n" + "="*80)
    print("üíæ SAUVEGARDE DES R√âSULTATS")
    print("="*80)

    # Cr√©er le dossier de sortie si n√©cessaire
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    # Colonnes √† garder (toutes les colonnes d'origine + les nouvelles)
    # Supprimer les colonnes temporaires
    cols_to_drop = ['is_validation_auto', 'validation_rank', 'Annee', 'D√©cision_Code']
    df_final = df_results.drop(columns=[col for col in cols_to_drop if col in df_results.columns])

    # R√©organiser les colonnes pour mettre les d√©cisions en premier
    decision_cols = ['Probabilit√©_Fond√©e', 'D√©cision_Mod√®le', 'D√©cision_Finale']
    other_cols = [col for col in df_final.columns if col not in decision_cols]
    df_final = df_final[decision_cols + other_cols]

    # Sauvegarder
    df_final.to_excel(output_path, index=False, engine='openpyxl')
    print(f"‚úÖ R√©sultats sauvegard√©s: {output_path}")
    print(f"   Nombre de lignes: {len(df_final)}")
    print(f"   Nombre de colonnes: {len(df_final.columns)}")

    # Afficher les premi√®res colonnes
    print(f"\nüìã Colonnes dans le fichier de sortie:")
    for i, col in enumerate(df_final.columns, 1):
        print(f"   {i:2d}. {col}")

    return df_final


def generate_summary_report(df_results, output_dir):
    """G√©n√©rer un rapport r√©capitulatif"""
    print("\n" + "="*80)
    print("üìù G√âN√âRATION DU RAPPORT R√âCAPITULATIF")
    print("="*80)

    report_path = output_dir / 'rapport_inference.txt'

    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("="*80 + "\n")
        f.write("RAPPORT D'INF√âRENCE - CatBoost\n")
        f.write("="*80 + "\n\n")

        f.write(f"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

        f.write("="*80 + "\n")
        f.write("R√âSUM√â DES PR√âDICTIONS\n")
        f.write("="*80 + "\n\n")

        total = len(df_results)

        # D√©cision Mod√®le
        f.write("D√âCISION MOD√àLE (avant r√®gle m√©tier):\n")
        for decision in ['Rejet Auto', 'Audit Humain', 'Validation Auto']:
            count = (df_results['D√©cision_Mod√®le'] == decision).sum()
            pct = 100 * count / total
            f.write(f"  {decision:20s}: {count:6d} ({pct:5.1f}%)\n")

        f.write(f"\n  TOTAL: {total}\n\n")

        # D√©cision Finale (apr√®s r√®gle)
        f.write("D√âCISION FINALE (apr√®s r√®gle m√©tier):\n")
        for decision in df_results['D√©cision_Finale'].unique():
            count = (df_results['D√©cision_Finale'] == decision).sum()
            pct = 100 * count / total
            f.write(f"  {decision:25s}: {count:6d} ({pct:5.1f}%)\n")

        f.write(f"\n  TOTAL: {total}\n\n")

        # Impact de la r√®gle
        n_blocked = ((df_results['D√©cision_Mod√®le'] == 'Validation Auto') &
                    (df_results['D√©cision_Finale'] == 'Audit Humain (R√®gle)')).sum()

        f.write("="*80 + "\n")
        f.write("IMPACT DE LA R√àGLE M√âTIER\n")
        f.write("="*80 + "\n\n")

        f.write(f"Validations bloqu√©es: {n_blocked}\n")
        if n_blocked > 0:
            f.write(f"Impact: {100*n_blocked/total:.2f}% des r√©clamations\n")

        f.write("\n")

        # Statistiques des probabilit√©s
        f.write("="*80 + "\n")
        f.write("STATISTIQUES DES PROBABILIT√âS\n")
        f.write("="*80 + "\n\n")

        probs = df_results['Probabilit√©_Fond√©e']
        f.write(f"Min       : {probs.min():.4f}\n")
        f.write(f"25%       : {probs.quantile(0.25):.4f}\n")
        f.write(f"M√©diane   : {probs.median():.4f}\n")
        f.write(f"Moyenne   : {probs.mean():.4f}\n")
        f.write(f"75%       : {probs.quantile(0.75):.4f}\n")
        f.write(f"Max       : {probs.max():.4f}\n\n")

        # Distribution par famille si disponible
        if 'Famille Produit' in df_results.columns:
            f.write("="*80 + "\n")
            f.write("DISTRIBUTION PAR FAMILLE DE PRODUIT\n")
            f.write("="*80 + "\n\n")

            family_stats = df_results.groupby('Famille Produit')['D√©cision_Finale'].value_counts().unstack(fill_value=0)

            for family in family_stats.index[:10]:  # Top 10
                total_fam = family_stats.loc[family].sum()
                f.write(f"\n{family[:50]:50s} (n={total_fam})\n")
                for decision in family_stats.columns:
                    count = family_stats.loc[family, decision]
                    pct = 100 * count / total_fam if total_fam > 0 else 0
                    f.write(f"  {decision:25s}: {count:5d} ({pct:5.1f}%)\n")

        f.write("\n" + "="*80 + "\n")
        f.write("FIN DU RAPPORT\n")
        f.write("="*80 + "\n")

    print(f"‚úÖ Rapport sauvegard√©: {report_path}")


def main():
    """Fonction principale"""
    parser = argparse.ArgumentParser(description='Inf√©rence CatBoost sur nouvelle base de donn√©es')
    parser.add_argument('--input_file', type=str, required=True,
                       help='Chemin vers le fichier Excel d\'entr√©e')
    parser.add_argument('--output_file', type=str, default=None,
                       help='Chemin vers le fichier Excel de sortie (optionnel)')
    parser.add_argument('--apply_rule', action='store_true',
                       help='Appliquer la r√®gle m√©tier (1 validation auto par client/an)')

    args = parser.parse_args()

    print("\n" + "="*80)
    print("üöÄ SCRIPT D'INF√âRENCE - CatBoost")
    print("="*80)

    # 1. Charger le mod√®le et preprocessor
    model, preprocessor, threshold_low, threshold_high = load_model_and_preprocessor()
    if model is None:
        return

    # 2. Charger les nouvelles donn√©es
    df = load_new_data(args.input_file)
    if df is None:
        return

    # 3. V√©rifier les colonnes
    if not verify_required_columns(df, preprocessor):
        return

    # 4. Preprocessing
    X_processed = preprocess_data(df, preprocessor)
    if X_processed is None:
        return

    # 5. Faire les pr√©dictions
    y_prob, decisions, decisions_code = make_predictions(model, X_processed, threshold_low, threshold_high)

    # 6. Ajouter les r√©sultats au dataframe original
    df_results = df.copy()
    df_results['Probabilit√©_Fond√©e'] = y_prob
    df_results['D√©cision_Mod√®le'] = decisions
    df_results['D√©cision_Code'] = decisions_code

    # 7. Appliquer la r√®gle m√©tier si demand√©
    if args.apply_rule:
        df_results = apply_business_rule(df_results)
    else:
        print("\n‚ö†Ô∏è  R√®gle m√©tier NON appliqu√©e (utilisez --apply_rule pour l'activer)")
        df_results['D√©cision_Finale'] = df_results['D√©cision_Mod√®le']

    # 8. D√©terminer le nom du fichier de sortie
    if args.output_file:
        output_path = Path(args.output_file)
    else:
        input_path = Path(args.input_file)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_path = Path('outputs/inference') / f'{input_path.stem}_predictions_{timestamp}.xlsx'

    # 9. Sauvegarder les r√©sultats
    df_final = save_results(df_results, output_path)

    # 10. G√©n√©rer le rapport
    generate_summary_report(df_results, output_path.parent)

    print("\n" + "="*80)
    print("‚úÖ INF√âRENCE TERMIN√âE")
    print("="*80)
    print(f"\nüìÇ Fichiers g√©n√©r√©s:")
    print(f"   - {output_path}")
    print(f"   - {output_path.parent / 'rapport_inference.txt'}")
    print("\nüí° Ouvrez le fichier Excel pour voir les pr√©dictions!")


if __name__ == '__main__':
    main()
