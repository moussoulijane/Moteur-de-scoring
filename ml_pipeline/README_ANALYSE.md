# Guide d'Analyse des RÃ©sultats - Moteur de Scoring

## ğŸ“‹ Vue d'ensemble

Ce dossier contient plusieurs scripts d'analyse pour Ã©valuer et prÃ©senter les performances des modÃ¨les de classification de rÃ©clamations bancaires.

## ğŸš€ Scripts disponibles

### 1. **model_comparison.py** - EntraÃ®nement et Comparaison
```bash
python ml_pipeline/model_comparison.py
```
**Objectif**: EntraÃ®ner les 3 modÃ¨les (XGBoost, RandomForest, CatBoost) et sauvegarder les prÃ©dictions.

**Sorties**:
- ModÃ¨les entraÃ®nÃ©s sauvegardÃ©s
- PrÃ©dictions sauvegardÃ©es dans `outputs/production/predictions/predictions_2025.pkl`
- Graphiques de comparaison

âš ï¸ **IMPORTANT**: ExÃ©cuter ce script EN PREMIER avant toute analyse!

---

### 2. **analyze_results.py** - Analyse XGBoost
```bash
python ml_pipeline/analyze_results.py
```
**Objectif**: Analyser en dÃ©tail les rÃ©sultats du modÃ¨le XGBoost.

**Visualisations gÃ©nÃ©rÃ©es**:
- âœ… Matrice de confusion (sur cas automatisÃ©s)
- âœ… Impact de la rÃ¨gle mÃ©tier (9 graphes)
- âœ… Accuracy par famille de produit
- âœ… Rapport texte rÃ©capitulatif

**Fichiers gÃ©nÃ©rÃ©s**:
```
outputs/production/figures/
â”œâ”€â”€ xgboost_confusion_matrix.png
â”œâ”€â”€ xgboost_business_rule_impact.png
â”œâ”€â”€ xgboost_accuracy_by_family.png
outputs/production/
â””â”€â”€ xgboost_rapport_analyse.txt
```

---

### 3. **analyze_results_catboost.py** - Analyse CatBoost
```bash
python ml_pipeline/analyze_results_catboost.py
```
**Objectif**: Analyser en dÃ©tail les rÃ©sultats du modÃ¨le CatBoost.

**Visualisations gÃ©nÃ©rÃ©es**:
- âœ… Matrice de confusion (colormap violet)
- âœ… Impact de la rÃ¨gle mÃ©tier (9 graphes)
- âœ… Accuracy par famille de produit
- âœ… Rapport texte rÃ©capitulatif

**Fichiers gÃ©nÃ©rÃ©s**:
```
outputs/production/figures/
â”œâ”€â”€ catboost_confusion_matrix.png
â”œâ”€â”€ catboost_business_rule_impact.png
â”œâ”€â”€ catboost_accuracy_by_family.png
outputs/production/
â””â”€â”€ catboost_rapport_analyse.txt
```

---

### 4. **generate_catboost_report.py** â­ - Rapport Professionnel CatBoost
```bash
python ml_pipeline/generate_catboost_report.py
```
**Objectif**: GÃ©nÃ©rer un **dossier complet de visualisations professionnelles** pour prÃ©senter les performances de CatBoost.

**ğŸ¯ RECOMMANDÃ‰ pour prÃ©sentation et valorisation des rÃ©sultats!**

**Visualisations gÃ©nÃ©rÃ©es** (6 PNG + 1 TXT):

#### ğŸ“Š 1. Dashboard de Performance
- Vue d'ensemble des mÃ©triques principales
- Matrice de confusion dÃ©taillÃ©e
- Distribution des 3 types de dÃ©cision
- Barplot des mÃ©triques (Accuracy, Precision, Recall, F1, SpÃ©cificitÃ©)
- Distribution des probabilitÃ©s par classe

#### ğŸ“ˆ 2. Courbes ROC et Precision-Recall
- Courbe ROC avec AUC
- Points marqueurs pour les seuils choisis (threshold_low et threshold_high)
- Courbe Precision-Recall
- Ligne de base (baseline)

#### ğŸ“… 3. Performance Temporelle
- Volume mensuel (total vs automatisÃ©)
- Ã‰volution du taux d'automatisation
- Ã‰volution des mÃ©triques (Accuracy, Precision, Recall)
- Table rÃ©capitulative mensuelle

#### ğŸ’° 4. Analyse par Montant
- Volume par tranche de montant
- Performance (Accuracy) et taux d'automatisation par tranche
- CoÃ»ts des erreurs (FP et FN) par tranche
- Nombre d'erreurs par tranche

#### ğŸ’¼ 5. Impact Business DÃ©taillÃ©
- Flux financier (Gain brut â†’ Pertes â†’ Gain NET)
- ROI unitaire par type de cas
- Composition des prÃ©dictions (pie chart TP/TN/FP/FN)
- RÃ©sumÃ© financier complet

#### ğŸ† 6. Top Families Advanced
- Accuracy par famille (Top 12)
- Volume et taux d'automatisation
- Scatter plot Precision vs Recall (avec volume et accuracy)
- Heatmap des mÃ©triques par famille

#### ğŸ“„ 7. Rapport Texte Complet
Rapport rÃ©capitulatif professionnel incluant:
- Vue d'ensemble
- SystÃ¨me Ã  3 zones
- MÃ©triques de performance
- Matrice de confusion dÃ©taillÃ©e
- Impact business
- Avantages du modÃ¨le
- Recommandations

**Dossier de sortie**:
```
outputs/production/catboost_report/
â”œâ”€â”€ 01_dashboard_performance.png
â”œâ”€â”€ 02_roc_pr_curves.png
â”œâ”€â”€ 03_performance_temporelle.png
â”œâ”€â”€ 04_analyse_par_montant.png
â”œâ”€â”€ 05_impact_business.png
â”œâ”€â”€ 06_top_families_advanced.png
â””â”€â”€ RAPPORT_CATBOOST.txt
```

---

## ğŸ”„ Workflow RecommandÃ©

### Pour l'entraÃ®nement initial:
```bash
# 1. EntraÃ®ner les modÃ¨les et sauvegarder les prÃ©dictions
python ml_pipeline/model_comparison.py

# 2. GÃ©nÃ©rer le rapport complet CatBoost (RECOMMANDÃ‰!)
python ml_pipeline/generate_catboost_report.py

# 3. (Optionnel) Analyser XGBoost sÃ©parÃ©ment
python ml_pipeline/analyze_results.py

# 4. (Optionnel) Analyser CatBoost avec rÃ¨gle mÃ©tier
python ml_pipeline/analyze_results_catboost.py
```

### Pour une prÃ©sentation professionnelle:
```bash
# Utiliser uniquement le gÃ©nÃ©rateur de rapport complet
python ml_pipeline/generate_catboost_report.py
```
**âœ… Ce script gÃ©nÃ¨re TOUT ce dont vous avez besoin pour prÃ©senter et valoriser votre travail!**

---

## ğŸ“Š Comprendre les Visualisations

### SystÃ¨me Ã  3 Zones de DÃ©cision

Le modÃ¨le utilise **2 seuils** pour crÃ©er **3 zones**:

```
Zone 1: prob â‰¤ threshold_low       â†’ REJET AUTO (Non FondÃ©e)
Zone 2: threshold_low < prob < threshold_high  â†’ AUDIT HUMAIN (manuel)
Zone 3: prob â‰¥ threshold_high      â†’ VALIDATION AUTO (FondÃ©e)
```

**Avantages**:
- âœ… Automatise les cas certains (zones 1 et 3)
- âœ… Envoie les cas incertains Ã  un expert humain (zone 2)
- âœ… RÃ©duit le risque d'erreur

### RÃ¨gle MÃ©tier

**RÃ¨gle appliquÃ©e**: Un client ne peut bÃ©nÃ©ficier que d'**UNE validation automatique par annÃ©e**.

**MÃ©canisme**:
1. Trier les rÃ©clamations par Date de Qualification
2. Par client et par annÃ©e, seule la **premiÃ¨re validation auto** est acceptÃ©e
3. Les validations suivantes deviennent des **audits humains**

**Impact**:
- ğŸ”’ PrÃ©vient l'abus de validations automatiques
- ğŸ“Š Augmente le nombre d'audits humains
- ğŸ’° Peut rÃ©duire le gain NET mais amÃ©liore le contrÃ´le

### MÃ©triques ClÃ©s

| MÃ©trique | Description | Objectif |
|----------|-------------|----------|
| **Accuracy** | Proportion de prÃ©dictions correctes | > 95% |
| **Precision** | Proportion de validations correctes parmi toutes les validations | > 90% |
| **Recall** | Proportion de rÃ©clamations fondÃ©es correctement validÃ©es | > 95% |
| **F1-Score** | Moyenne harmonique Precision/Recall | > 92% |
| **Taux d'automatisation** | Proportion de cas automatisÃ©s (hors audit) | 70-80% |
| **Gain NET** | Gain brut - CoÃ»t FP - CoÃ»t FN | Positif |

### Calcul du Gain NET

```
Gain Brut = (TP + TN) Ã— 169 DH
CoÃ»t FP = Î£ montants des faux positifs
CoÃ»t FN = 2 Ã— Î£ montants des faux nÃ©gatifs  (coÃ»t double!)
Gain NET = Gain Brut - CoÃ»t FP - CoÃ»t FN
```

---

## ğŸ¨ Palette de Couleurs

Les visualisations utilisent un code couleur cohÃ©rent:

| Couleur | Usage |
|---------|-------|
| ğŸŸ¢ Vert | Positif (TP, TN, Gain, Bonne performance) |
| ğŸ”µ Bleu | Neutre (Volume, Accuracy, Informations) |
| ğŸŸ  Orange | Attention (FP, CoÃ»ts modÃ©rÃ©s) |
| ğŸ”´ Rouge | NÃ©gatif (FN, Pertes, Erreurs) |
| ğŸŸ£ Violet | CatBoost, MÃ©triques spÃ©ciales |

---

## ğŸ“ Structure des Sorties

```
outputs/production/
â”œâ”€â”€ predictions/
â”‚   â””â”€â”€ predictions_2025.pkl         # PrÃ©dictions sauvegardÃ©es
â”œâ”€â”€ figures/
â”‚   â”œâ”€â”€ xgboost_confusion_matrix.png
â”‚   â”œâ”€â”€ xgboost_business_rule_impact.png
â”‚   â”œâ”€â”€ xgboost_accuracy_by_family.png
â”‚   â”œâ”€â”€ catboost_confusion_matrix.png
â”‚   â”œâ”€â”€ catboost_business_rule_impact.png
â”‚   â””â”€â”€ catboost_accuracy_by_family.png
â”œâ”€â”€ catboost_report/                 # â­ DOSSIER COMPLET
â”‚   â”œâ”€â”€ 01_dashboard_performance.png
â”‚   â”œâ”€â”€ 02_roc_pr_curves.png
â”‚   â”œâ”€â”€ 03_performance_temporelle.png
â”‚   â”œâ”€â”€ 04_analyse_par_montant.png
â”‚   â”œâ”€â”€ 05_impact_business.png
â”‚   â”œâ”€â”€ 06_top_families_advanced.png
â”‚   â””â”€â”€ RAPPORT_CATBOOST.txt
â”œâ”€â”€ xgboost_rapport_analyse.txt
â””â”€â”€ catboost_rapport_analyse.txt
```

---

## ğŸ’¡ Conseils pour la PrÃ©sentation

### Pour valoriser votre travail:

1. **Commencer par le Dashboard** (`01_dashboard_performance.png`)
   - Montre immÃ©diatement la performance globale
   - MÃ©triques clÃ©s visibles d'un coup d'Å“il

2. **Expliquer le systÃ¨me Ã  3 zones**
   - Utiliser le graphique de distribution des dÃ©cisions
   - Montrer la distribution des probabilitÃ©s

3. **Montrer l'impact business** (`05_impact_business.png`)
   - Flux financier clair
   - ROI positif
   - Gain NET significatif

4. **DÃ©tailler les analyses** (selon l'audience)
   - Performance temporelle (Ã©volution)
   - Performance par montant (robustesse)
   - Performance par famille (granularitÃ©)

5. **Terminer par les recommandations**
   - Lire le rapport texte
   - Mettre en avant les points forts
   - Proposer des axes d'amÃ©lioration

### Points Ã  mettre en avant:

âœ… **Taux d'automatisation Ã©levÃ©** (70-80%)
âœ… **Accuracy > 98%** sur cas automatisÃ©s
âœ… **Gain NET positif**
âœ… **Robustesse** (gestion valeurs manquantes, catÃ©gorielles)
âœ… **Gestion de l'incertitude** (zone d'audit humain)
âœ… **ContrÃ´le business** (rÃ¨gle mÃ©tier personnalisable)

---

## ğŸ”§ Personnalisation

### Modifier les seuils
Ã‰diter dans `model_comparison.py`:
```python
threshold_low, threshold_high = optimize_dual_thresholds(...)
```

### Modifier la rÃ¨gle mÃ©tier
Ã‰diter dans `analyze_results.py` ou `analyze_results_catboost.py`:
```python
# Exemple: 2 validations auto par an au lieu de 1
df_scenario['validation_rank'] > 2  # au lieu de > 1
```

### Ajouter des visualisations
Ajouter des fonctions `viz_N_...()` dans `generate_catboost_report.py`

---

## â“ FAQ

**Q: Quel script utiliser pour une prÃ©sentation professionnelle?**
A: `generate_catboost_report.py` - Il gÃ©nÃ¨re tout ce dont vous avez besoin!

**Q: Pourquoi CatBoost et pas XGBoost?**
A: CatBoost offre gÃ©nÃ©ralement de meilleures performances sur des donnÃ©es catÃ©gorielles et gÃ¨re mieux les valeurs manquantes sans preprocessing.

**Q: Comment expliquer les 2 seuils?**
A: Le seuil bas filtre les rejets Ã©vidents, le seuil haut filtre les validations Ã©videntes. Entre les deux = incertitude â†’ audit humain.

**Q: Pourquoi le coÃ»t FN est Ã— 2?**
A: Car rejeter une rÃ©clamation fondÃ©e coÃ»te plus cher (insatisfaction client, coÃ»ts lÃ©gaux potentiels).

**Q: Puis-je dÃ©sactiver la rÃ¨gle mÃ©tier?**
A: Oui, comparer les graphiques "SANS rÃ¨gle" vs "AVEC rÃ¨gle" pour dÃ©cider.

---

## ğŸ“ Support

Pour toute question ou problÃ¨me:
1. VÃ©rifier que `model_comparison.py` a Ã©tÃ© exÃ©cutÃ© en premier
2. VÃ©rifier que le fichier `predictions_2025.pkl` existe
3. Consulter les logs d'exÃ©cution pour identifier les erreurs

---

**CrÃ©Ã© avec â¤ï¸ pour valoriser votre travail de machine learning!**
