"""
RAPPORT COMPLET DE PERFORMANCE - CatBoost
G√©n√®re un dossier professionnel avec toutes les visualisations
pour pr√©senter et valoriser les r√©sultats du mod√®le
Usage: python generate_catboost_report.py
"""
import sys
sys.path.append('src')

import pandas as pd
import numpy as np
import joblib
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import (
    confusion_matrix, accuracy_score, precision_score, recall_score,
    f1_score, roc_curve, auc, precision_recall_curve, classification_report
)
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# Configuration
sns.set_style('whitegrid')
sns.set_palette('husl')
PRIX_UNITAIRE_DH = 169

# Cr√©er le dossier de sortie
OUTPUT_DIR = Path('outputs/production/catboost_report')
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)


def load_data():
    """Charger les donn√©es et pr√©dictions CatBoost"""
    print("\n" + "="*80)
    print("üìÇ CHARGEMENT DES DONN√âES")
    print("="*80)

    # Charger les donn√©es 2025
    df_2025 = pd.read_excel('data/raw/reclamations_2025.xlsx')
    print(f"‚úÖ Donn√©es 2025: {len(df_2025)} r√©clamations")

    # Charger les pr√©dictions
    predictions_path = Path('outputs/production/predictions/predictions_2025.pkl')

    if not predictions_path.exists():
        print("‚ùå Fichier de pr√©dictions non trouv√©!")
        print("   Ex√©cutez d'abord: python model_comparison.py")
        return None, None, None

    predictions_data = joblib.load(predictions_path)

    if 'CatBoost' not in predictions_data:
        print("‚ùå CatBoost non trouv√© dans les pr√©dictions!")
        return None, None, None

    y_true = predictions_data['y_true']
    catboost_data = predictions_data['CatBoost']

    print(f"‚úÖ Pr√©dictions CatBoost charg√©es")
    print(f"   Seuils: {catboost_data['threshold_low']:.4f} / {catboost_data['threshold_high']:.4f}")

    return df_2025, y_true, catboost_data


def create_3zone_predictions(y_prob, threshold_low, threshold_high):
    """Cr√©er les pr√©dictions avec 3 zones"""
    y_pred = np.full(len(y_prob), -1, dtype=int)
    y_pred[y_prob <= threshold_low] = 0
    y_pred[y_prob >= threshold_high] = 1
    return y_pred


def viz_1_dashboard_performance(df, y_true, y_prob, threshold_low, threshold_high):
    """Visualisation 1: Dashboard de performance globale"""
    print("\nüìä G√©n√©ration: Dashboard de performance globale...")

    y_pred = create_3zone_predictions(y_prob, threshold_low, threshold_high)
    mask_auto = (y_pred != -1)
    y_true_auto = y_true[mask_auto]
    y_pred_auto = y_pred[mask_auto]

    # Calculer les m√©triques
    cm = confusion_matrix(y_true_auto, y_pred_auto)
    tn, fp, fn, tp = cm.ravel()

    accuracy = accuracy_score(y_true_auto, y_pred_auto)
    precision = precision_score(y_true_auto, y_pred_auto, zero_division=0)
    recall = recall_score(y_true_auto, y_pred_auto, zero_division=0)
    f1 = f1_score(y_true_auto, y_pred_auto, zero_division=0)
    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0

    taux_auto = 100 * mask_auto.sum() / len(y_pred)

    # Cr√©er la figure
    fig = plt.figure(figsize=(18, 12))
    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)

    fig.suptitle('DASHBOARD DE PERFORMANCE - CatBoost',
                 fontsize=18, fontweight='bold', y=0.98)

    # 1. M√©triques principales (texte)
    ax1 = fig.add_subplot(gs[0, :])
    ax1.axis('off')

    metrics_text = f"""
    üéØ M√âTRIQUES PRINCIPALES - CatBoost

    Taux d'automatisation: {taux_auto:.1f}%  |  Cas automatis√©s: {mask_auto.sum():,}/{len(y_pred):,}  |  Cas en audit: {(~mask_auto).sum():,}

    Accuracy: {accuracy:.2%}  |  Precision: {precision:.2%}  |  Recall (Sensibilit√©): {recall:.2%}  |  F1-Score: {f1:.2%}  |  Sp√©cificit√©: {specificity:.2%}

    TP: {tp}  |  TN: {tn}  |  FP: {fp}  |  FN: {fn}  |  Total Erreurs: {fp+fn}
    """

    ax1.text(0.5, 0.5, metrics_text, transform=ax1.transAxes,
            fontsize=12, verticalalignment='center', horizontalalignment='center',
            family='monospace', bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.3))

    # 2. Matrice de confusion
    ax2 = fig.add_subplot(gs[1, 0])
    cm_percent = cm.astype('float') / cm.sum() * 100

    annotations = []
    for i in range(2):
        row = []
        for j in range(2):
            row.append(f'{cm[i,j]}\n({cm_percent[i,j]:.1f}%)')
        annotations.append(row)

    sns.heatmap(cm, annot=annotations, fmt='', cmap='Purples', ax=ax2,
                xticklabels=['Non Fond√©e', 'Fond√©e'],
                yticklabels=['Non Fond√©e', 'Fond√©e'],
                cbar_kws={'label': 'Nombre'}, annot_kws={'size': 11, 'weight': 'bold'})
    ax2.set_xlabel('Pr√©diction', fontweight='bold')
    ax2.set_ylabel('R√©alit√©', fontweight='bold')
    ax2.set_title('Matrice de Confusion', fontweight='bold', fontsize=12)

    # 3. Distribution des d√©cisions
    ax3 = fig.add_subplot(gs[1, 1])

    decisions = ['Rejet\nAuto', 'Audit\nHumain', 'Validation\nAuto']
    counts = [
        (y_pred == 0).sum(),
        (y_pred == -1).sum(),
        (y_pred == 1).sum()
    ]
    colors_dec = ['#e74c3c', '#f39c12', '#2ecc71']

    bars = ax3.bar(decisions, counts, color=colors_dec, alpha=0.8, edgecolor='black', linewidth=1.5)
    ax3.set_ylabel('Nombre de cas', fontweight='bold')
    ax3.set_title('Distribution des D√©cisions', fontweight='bold', fontsize=12)
    ax3.grid(True, alpha=0.3, axis='y')

    for bar, count in zip(bars, counts):
        height = bar.get_height()
        pct = 100 * count / len(y_pred)
        ax3.text(bar.get_x() + bar.get_width()/2., height + 100,
               f'{int(count)}\n({pct:.1f}%)', ha='center', va='bottom',
               fontsize=10, fontweight='bold')

    # 4. Barplot des m√©triques
    ax4 = fig.add_subplot(gs[1, 2])

    metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'Sp√©cificit√©']
    metrics_values = [accuracy, precision, recall, f1, specificity]
    colors_met = ['#3498db', '#9b59b6', '#e74c3c', '#f39c12', '#2ecc71']

    bars = ax4.barh(metrics_names, metrics_values, color=colors_met, alpha=0.8, edgecolor='black', linewidth=1)
    ax4.set_xlabel('Score', fontweight='bold')
    ax4.set_title('M√©triques de Performance', fontweight='bold', fontsize=12)
    ax4.set_xlim([0, 1])
    ax4.grid(True, alpha=0.3, axis='x')

    for bar, val in zip(bars, metrics_values):
        width = bar.get_width()
        ax4.text(width + 0.01, bar.get_y() + bar.get_height()/2.,
               f'{val:.2%}', ha='left', va='center', fontsize=9, fontweight='bold')

    # 5. Distribution des probabilit√©s (Fond√©e vs Non Fond√©e)
    ax5 = fig.add_subplot(gs[2, :])

    mask_fondee = (y_true == 1)
    mask_non_fondee = (y_true == 0)

    ax5.hist(y_prob[mask_fondee], bins=50, alpha=0.6, label='Fond√©e (vraie)',
            color='#2ecc71', edgecolor='black', linewidth=0.5)
    ax5.hist(y_prob[mask_non_fondee], bins=50, alpha=0.6, label='Non Fond√©e (vraie)',
            color='#e74c3c', edgecolor='black', linewidth=0.5)

    ax5.axvline(threshold_low, color='blue', linestyle='--', linewidth=2,
               label=f'Seuil bas = {threshold_low:.3f}')
    ax5.axvline(threshold_high, color='red', linestyle='--', linewidth=2,
               label=f'Seuil haut = {threshold_high:.3f}')

    ax5.set_xlabel('Probabilit√© pr√©dite (Fond√©e)', fontweight='bold')
    ax5.set_ylabel('Fr√©quence', fontweight='bold')
    ax5.set_title('Distribution des Probabilit√©s par Classe R√©elle', fontweight='bold', fontsize=12)
    ax5.legend(loc='upper center', ncol=4)
    ax5.grid(True, alpha=0.3)

    plt.tight_layout()
    output_path = OUTPUT_DIR / '01_dashboard_performance.png'
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"   ‚úÖ Sauvegard√©: {output_path.name}")
    plt.close()


def viz_2_roc_pr_curves(y_true, y_prob, threshold_low, threshold_high):
    """Visualisation 2: Courbes ROC et Precision-Recall"""
    print("\nüìä G√©n√©ration: Courbes ROC et Precision-Recall...")

    # Calculer ROC
    fpr, tpr, thresholds_roc = roc_curve(y_true, y_prob)
    roc_auc = auc(fpr, tpr)

    # Calculer Precision-Recall
    precision_vals, recall_vals, thresholds_pr = precision_recall_curve(y_true, y_prob)

    # Cr√©er la figure
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))
    fig.suptitle('COURBES DE PERFORMANCE - CatBoost', fontsize=16, fontweight='bold')

    # 1. ROC Curve
    ax1.plot(fpr, tpr, color='#9b59b6', linewidth=2.5, label=f'ROC (AUC = {roc_auc:.3f})')
    ax1.plot([0, 1], [0, 1], 'k--', linewidth=1.5, label='Hasard (AUC = 0.5)')

    # Marquer les seuils choisis
    y_pred_low = (y_prob >= threshold_low).astype(int)
    y_pred_high = (y_prob >= threshold_high).astype(int)

    # Point pour threshold_low
    idx_low = np.argmin(np.abs(thresholds_roc - threshold_low))
    ax1.scatter(fpr[idx_low], tpr[idx_low], color='blue', s=200, zorder=5,
               marker='o', edgecolor='black', linewidth=2, label=f'Seuil bas ({threshold_low:.3f})')

    # Point pour threshold_high
    idx_high = np.argmin(np.abs(thresholds_roc - threshold_high))
    ax1.scatter(fpr[idx_high], tpr[idx_high], color='red', s=200, zorder=5,
               marker='s', edgecolor='black', linewidth=2, label=f'Seuil haut ({threshold_high:.3f})')

    ax1.set_xlabel('Taux de Faux Positifs (FPR)', fontweight='bold', fontsize=11)
    ax1.set_ylabel('Taux de Vrais Positifs (TPR)', fontweight='bold', fontsize=11)
    ax1.set_title('Courbe ROC', fontweight='bold', fontsize=13)
    ax1.legend(loc='lower right')
    ax1.grid(True, alpha=0.3)

    # 2. Precision-Recall Curve
    ax2.plot(recall_vals, precision_vals, color='#e74c3c', linewidth=2.5, label='Precision-Recall')

    # Ligne de base (proportion de positifs)
    baseline = y_true.sum() / len(y_true)
    ax2.axhline(baseline, color='k', linestyle='--', linewidth=1.5,
               label=f'Baseline ({baseline:.2%})')

    ax2.set_xlabel('Recall (Sensibilit√©)', fontweight='bold', fontsize=11)
    ax2.set_ylabel('Precision', fontweight='bold', fontsize=11)
    ax2.set_title('Courbe Precision-Recall', fontweight='bold', fontsize=13)
    ax2.legend(loc='best')
    ax2.grid(True, alpha=0.3)
    ax2.set_xlim([0, 1])
    ax2.set_ylim([0, 1])

    plt.tight_layout()
    output_path = OUTPUT_DIR / '02_roc_pr_curves.png'
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"   ‚úÖ Sauvegard√©: {output_path.name}")
    plt.close()


def viz_3_performance_temporelle(df, y_true, y_prob, threshold_low, threshold_high):
    """Visualisation 3: Performance par p√©riode"""
    print("\nüìä G√©n√©ration: Performance temporelle...")

    df_analysis = df.copy()
    df_analysis['y_true'] = y_true
    df_analysis['y_prob'] = y_prob
    df_analysis['y_pred'] = create_3zone_predictions(y_prob, threshold_low, threshold_high)

    # Convertir la date
    df_analysis['Date de Qualification'] = pd.to_datetime(
        df_analysis['Date de Qualification'], errors='coerce'
    )
    df_analysis['Mois'] = df_analysis['Date de Qualification'].dt.to_period('M')

    # Calculer les m√©triques par mois
    monthly_stats = []

    for month in sorted(df_analysis['Mois'].dropna().unique()):
        mask_month = df_analysis['Mois'] == month
        df_month = df_analysis[mask_month]

        y_pred_month = df_month['y_pred'].values
        y_true_month = df_month['y_true'].values

        # Seulement sur cas automatis√©s
        mask_auto = (y_pred_month != -1)

        if mask_auto.sum() > 0:
            y_true_auto = y_true_month[mask_auto]
            y_pred_auto = y_pred_month[mask_auto]

            accuracy = accuracy_score(y_true_auto, y_pred_auto)
            precision = precision_score(y_true_auto, y_pred_auto, zero_division=0)
            recall = recall_score(y_true_auto, y_pred_auto, zero_division=0)

            monthly_stats.append({
                'Mois': str(month),
                'Volume': len(df_month),
                'Automatis√©s': mask_auto.sum(),
                'Taux_Auto': 100 * mask_auto.sum() / len(df_month),
                'Accuracy': accuracy,
                'Precision': precision,
                'Recall': recall
            })

    df_monthly = pd.DataFrame(monthly_stats)

    if len(df_monthly) == 0:
        print("   ‚ö†Ô∏è  Pas assez de donn√©es temporelles")
        return

    # Cr√©er la figure
    fig, axes = plt.subplots(2, 2, figsize=(18, 12))
    fig.suptitle('PERFORMANCE TEMPORELLE - CatBoost', fontsize=16, fontweight='bold')

    # 1. Volume par mois
    ax1 = axes[0, 0]
    ax1.bar(range(len(df_monthly)), df_monthly['Volume'], color='#3498db', alpha=0.7, label='Total')
    ax1.bar(range(len(df_monthly)), df_monthly['Automatis√©s'], color='#2ecc71', alpha=0.7, label='Automatis√©s')
    ax1.set_xticks(range(len(df_monthly)))
    ax1.set_xticklabels(df_monthly['Mois'], rotation=45, ha='right')
    ax1.set_ylabel('Nombre de r√©clamations', fontweight='bold')
    ax1.set_title('Volume par Mois', fontweight='bold', fontsize=12)
    ax1.legend()
    ax1.grid(True, alpha=0.3, axis='y')

    # 2. Taux d'automatisation
    ax2 = axes[0, 1]
    ax2.plot(range(len(df_monthly)), df_monthly['Taux_Auto'], marker='o',
            linewidth=2.5, markersize=8, color='#e74c3c')
    ax2.set_xticks(range(len(df_monthly)))
    ax2.set_xticklabels(df_monthly['Mois'], rotation=45, ha='right')
    ax2.set_ylabel('Taux d\'automatisation (%)', fontweight='bold')
    ax2.set_title('√âvolution du Taux d\'Automatisation', fontweight='bold', fontsize=12)
    ax2.grid(True, alpha=0.3)
    ax2.set_ylim([0, 100])

    # 3. M√©triques de performance
    ax3 = axes[1, 0]
    x_pos = range(len(df_monthly))
    ax3.plot(x_pos, df_monthly['Accuracy'], marker='o', linewidth=2, markersize=7, label='Accuracy', color='#3498db')
    ax3.plot(x_pos, df_monthly['Precision'], marker='s', linewidth=2, markersize=7, label='Precision', color='#9b59b6')
    ax3.plot(x_pos, df_monthly['Recall'], marker='^', linewidth=2, markersize=7, label='Recall', color='#e74c3c')
    ax3.set_xticks(x_pos)
    ax3.set_xticklabels(df_monthly['Mois'], rotation=45, ha='right')
    ax3.set_ylabel('Score', fontweight='bold')
    ax3.set_title('√âvolution des M√©triques', fontweight='bold', fontsize=12)
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    ax3.set_ylim([0.8, 1.0])

    # 4. Table r√©capitulative
    ax4 = axes[1, 1]
    ax4.axis('off')

    table_data = []
    for _, row in df_monthly.iterrows():
        table_data.append([
            row['Mois'],
            f"{row['Volume']:,}",
            f"{row['Taux_Auto']:.1f}%",
            f"{row['Accuracy']:.2%}"
        ])

    table = ax4.table(cellText=table_data,
                     colLabels=['Mois', 'Volume', 'Taux Auto', 'Accuracy'],
                     cellLoc='center', loc='center',
                     colWidths=[0.3, 0.2, 0.25, 0.25])
    table.auto_set_font_size(False)
    table.set_fontsize(9)
    table.scale(1, 2)

    # Style du header
    for i in range(4):
        table[(0, i)].set_facecolor('#3498db')
        table[(0, i)].set_text_props(weight='bold', color='white')

    ax4.set_title('R√©sum√© Mensuel', fontweight='bold', fontsize=12, pad=20)

    plt.tight_layout()
    output_path = OUTPUT_DIR / '03_performance_temporelle.png'
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"   ‚úÖ Sauvegard√©: {output_path.name}")
    plt.close()


def viz_4_analyse_par_montant(df, y_true, y_prob, threshold_low, threshold_high):
    """Visualisation 4: Performance par tranche de montant"""
    print("\nüìä G√©n√©ration: Analyse par montant...")

    df_analysis = df.copy()
    df_analysis['y_true'] = y_true
    df_analysis['y_prob'] = y_prob
    df_analysis['y_pred'] = create_3zone_predictions(y_prob, threshold_low, threshold_high)

    # Nettoyer les montants
    df_analysis['Montant'] = pd.to_numeric(df_analysis['Montant demand√©'], errors='coerce').fillna(0)
    df_analysis['Montant'] = np.clip(df_analysis['Montant'], 0, np.percentile(df_analysis['Montant'], 99))

    # Cr√©er des tranches de montant
    bins = [0, 100, 500, 1000, 2000, 5000, 10000, np.inf]
    labels = ['0-100', '100-500', '500-1K', '1K-2K', '2K-5K', '5K-10K', '10K+']
    df_analysis['Tranche_Montant'] = pd.cut(df_analysis['Montant'], bins=bins, labels=labels)

    # Calculer les stats par tranche
    tranche_stats = []

    for tranche in labels:
        mask_tranche = df_analysis['Tranche_Montant'] == tranche
        df_tranche = df_analysis[mask_tranche]

        if len(df_tranche) == 0:
            continue

        y_pred_tranche = df_tranche['y_pred'].values
        y_true_tranche = df_tranche['y_true'].values

        mask_auto = (y_pred_tranche != -1)

        if mask_auto.sum() > 0:
            y_true_auto = y_true_tranche[mask_auto]
            y_pred_auto = y_pred_tranche[mask_auto]

            accuracy = accuracy_score(y_true_auto, y_pred_auto)

            # Erreurs co√ªteuses
            montants_auto = df_tranche[mask_auto]['Montant'].values
            fp_mask = (y_true_auto == 0) & (y_pred_auto == 1)
            fn_mask = (y_true_auto == 1) & (y_pred_auto == 0)

            cout_fp = montants_auto[fp_mask].sum()
            cout_fn = 2 * montants_auto[fn_mask].sum()

            tranche_stats.append({
                'Tranche': tranche,
                'Volume': len(df_tranche),
                'Automatis√©s': mask_auto.sum(),
                'Taux_Auto': 100 * mask_auto.sum() / len(df_tranche),
                'Accuracy': accuracy,
                'FP': fp_mask.sum(),
                'FN': fn_mask.sum(),
                'Co√ªt_FP': cout_fp,
                'Co√ªt_FN': cout_fn,
                'Co√ªt_Total': cout_fp + cout_fn
            })

    df_tranches = pd.DataFrame(tranche_stats)

    if len(df_tranches) == 0:
        print("   ‚ö†Ô∏è  Pas assez de donn√©es par tranche")
        return

    # Cr√©er la figure
    fig, axes = plt.subplots(2, 2, figsize=(18, 12))
    fig.suptitle('ANALYSE PAR TRANCHE DE MONTANT - CatBoost', fontsize=16, fontweight='bold')

    # 1. Volume par tranche
    ax1 = axes[0, 0]
    x_pos = range(len(df_tranches))
    ax1.bar(x_pos, df_tranches['Volume'], color='#3498db', alpha=0.7, edgecolor='black', linewidth=1)
    ax1.set_xticks(x_pos)
    ax1.set_xticklabels(df_tranches['Tranche'], rotation=45, ha='right')
    ax1.set_ylabel('Nombre de cas', fontweight='bold')
    ax1.set_title('Volume par Tranche de Montant', fontweight='bold', fontsize=12)
    ax1.grid(True, alpha=0.3, axis='y')

    for i, row in df_tranches.iterrows():
        ax1.text(i, row['Volume'] + 50, f"{int(row['Volume'])}",
                ha='center', va='bottom', fontsize=9, fontweight='bold')

    # 2. Accuracy et Taux d'automatisation
    ax2 = axes[0, 1]
    ax2_twin = ax2.twinx()

    bars = ax2.bar(x_pos, df_tranches['Accuracy'] * 100, color='#2ecc71',
                   alpha=0.6, label='Accuracy', edgecolor='black', linewidth=1)
    line = ax2_twin.plot(x_pos, df_tranches['Taux_Auto'], color='#e74c3c',
                        marker='o', linewidth=2.5, markersize=8, label='Taux Auto')

    ax2.set_xticks(x_pos)
    ax2.set_xticklabels(df_tranches['Tranche'], rotation=45, ha='right')
    ax2.set_ylabel('Accuracy (%)', fontweight='bold', color='#2ecc71')
    ax2_twin.set_ylabel('Taux Automatisation (%)', fontweight='bold', color='#e74c3c')
    ax2.set_title('Performance par Tranche', fontweight='bold', fontsize=12)
    ax2.tick_params(axis='y', labelcolor='#2ecc71')
    ax2_twin.tick_params(axis='y', labelcolor='#e74c3c')
    ax2.grid(True, alpha=0.3)
    ax2.set_ylim([90, 100])
    ax2_twin.set_ylim([0, 100])

    # 3. Co√ªts des erreurs
    ax3 = axes[1, 0]
    width = 0.35
    bars1 = ax3.bar(np.array(x_pos) - width/2, df_tranches['Co√ªt_FP'], width,
                   label='Co√ªt FP', color='#e67e22', alpha=0.8, edgecolor='black', linewidth=1)
    bars2 = ax3.bar(np.array(x_pos) + width/2, df_tranches['Co√ªt_FN'], width,
                   label='Co√ªt FN (√ó2)', color='#c0392b', alpha=0.8, edgecolor='black', linewidth=1)

    ax3.set_xticks(x_pos)
    ax3.set_xticklabels(df_tranches['Tranche'], rotation=45, ha='right')
    ax3.set_ylabel('Co√ªt (DH)', fontweight='bold')
    ax3.set_title('Co√ªt des Erreurs par Tranche', fontweight='bold', fontsize=12)
    ax3.legend()
    ax3.grid(True, alpha=0.3, axis='y')
    ax3.ticklabel_format(style='plain', axis='y')

    # 4. Nombre d'erreurs
    ax4 = axes[1, 1]
    bars1 = ax4.bar(np.array(x_pos) - width/2, df_tranches['FP'], width,
                   label='Faux Positifs', color='#e67e22', alpha=0.8, edgecolor='black', linewidth=1)
    bars2 = ax4.bar(np.array(x_pos) + width/2, df_tranches['FN'], width,
                   label='Faux N√©gatifs', color='#9b59b6', alpha=0.8, edgecolor='black', linewidth=1)

    ax4.set_xticks(x_pos)
    ax4.set_xticklabels(df_tranches['Tranche'], rotation=45, ha='right')
    ax4.set_ylabel('Nombre d\'erreurs', fontweight='bold')
    ax4.set_title('Erreurs par Tranche', fontweight='bold', fontsize=12)
    ax4.legend()
    ax4.grid(True, alpha=0.3, axis='y')

    plt.tight_layout()
    output_path = OUTPUT_DIR / '04_analyse_par_montant.png'
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"   ‚úÖ Sauvegard√©: {output_path.name}")
    plt.close()


def viz_5_impact_business(df, y_true, y_prob, threshold_low, threshold_high):
    """Visualisation 5: Impact business d√©taill√©"""
    print("\nüìä G√©n√©ration: Impact business...")

    df_analysis = df.copy()
    df_analysis['y_true'] = y_true
    df_analysis['y_prob'] = y_prob
    df_analysis['y_pred'] = create_3zone_predictions(y_prob, threshold_low, threshold_high)

    # Nettoyer les montants
    montants = pd.to_numeric(df_analysis['Montant demand√©'], errors='coerce').fillna(0)
    montants = np.clip(montants, 0, np.percentile(montants, 99))

    # Cas automatis√©s
    mask_auto = (df_analysis['y_pred'] != -1)
    y_true_auto = y_true[mask_auto]
    y_pred_auto = df_analysis['y_pred'][mask_auto].values
    montants_auto = montants[mask_auto]

    # Calculer les m√©triques business
    tp_mask = (y_true_auto == 1) & (y_pred_auto == 1)
    tn_mask = (y_true_auto == 0) & (y_pred_auto == 0)
    fp_mask = (y_true_auto == 0) & (y_pred_auto == 1)
    fn_mask = (y_true_auto == 1) & (y_pred_auto == 0)

    n_tp = tp_mask.sum()
    n_tn = tn_mask.sum()
    n_fp = fp_mask.sum()
    n_fn = fn_mask.sum()

    gain_brut = (n_tp + n_tn) * PRIX_UNITAIRE_DH
    cout_fp = montants_auto[fp_mask].sum()
    cout_fn = 2 * montants_auto[fn_mask].sum()
    gain_net = gain_brut - cout_fp - cout_fn

    # Cr√©er la figure
    fig = plt.figure(figsize=(18, 10))
    gs = fig.add_gridspec(2, 3, hspace=0.3, wspace=0.3)

    fig.suptitle('IMPACT BUSINESS - CatBoost', fontsize=16, fontweight='bold', y=0.98)

    # 1. Flux financier (Sankey-like visualization)
    ax1 = fig.add_subplot(gs[0, :])

    categories = ['Gain\nBrut', 'Perte\nFP', 'Perte\nFN', 'Gain\nNET']
    values = [gain_brut, -cout_fp, -cout_fn, gain_net]
    colors_flux = ['#27ae60', '#e74c3c', '#c0392b', '#2980b9']

    bars = ax1.bar(categories, values, color=colors_flux, alpha=0.8, edgecolor='black', linewidth=2)
    ax1.axhline(y=0, color='black', linestyle='-', linewidth=2)
    ax1.set_ylabel('Montant (DH)', fontweight='bold', fontsize=12)
    ax1.set_title('Flux Financier du Mod√®le', fontweight='bold', fontsize=14)
    ax1.grid(True, alpha=0.3, axis='y')
    ax1.ticklabel_format(style='plain', axis='y')

    for bar, val in zip(bars, values):
        height = bar.get_height()
        label_y = height + 10000 if height > 0 else height - 10000
        ax1.text(bar.get_x() + bar.get_width()/2., label_y,
               f'{val:,.0f} DH', ha='center', va='bottom' if height > 0 else 'top',
               fontsize=11, fontweight='bold')

    # 2. ROI par cas automatis√©
    ax2 = fig.add_subplot(gs[1, 0])

    roi_data = {
        'Gain par\ncas correct': PRIX_UNITAIRE_DH,
        'Co√ªt moyen\npar FP': cout_fp / n_fp if n_fp > 0 else 0,
        'Co√ªt moyen\npar FN': (2 * montants_auto[fn_mask].mean()) if n_fn > 0 else 0,
        'Gain NET\npar cas auto': gain_net / mask_auto.sum() if mask_auto.sum() > 0 else 0
    }

    bars = ax2.bar(roi_data.keys(), roi_data.values(),
                  color=['#27ae60', '#e67e22', '#c0392b', '#3498db'],
                  alpha=0.8, edgecolor='black', linewidth=1.5)
    ax2.set_ylabel('Montant (DH)', fontweight='bold')
    ax2.set_title('ROI Unitaire', fontweight='bold', fontsize=12)
    ax2.grid(True, alpha=0.3, axis='y')
    ax2.tick_params(axis='x', rotation=15)

    for bar, val in zip(bars, roi_data.values()):
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height + 5,
               f'{val:.0f}', ha='center', va='bottom', fontsize=9, fontweight='bold')

    # 3. Composition du gain
    ax3 = fig.add_subplot(gs[1, 1])

    sizes = [n_tp, n_tn, n_fp, n_fn]
    labels_pie = [f'TP\n{n_tp}', f'TN\n{n_tn}', f'FP\n{n_fp}', f'FN\n{n_fn}']
    colors_pie = ['#2ecc71', '#3498db', '#e67e22', '#c0392b']
    explode = (0.05, 0.05, 0.1, 0.1)

    wedges, texts, autotexts = ax3.pie(sizes, labels=labels_pie, colors=colors_pie,
                                       autopct='%1.1f%%', startangle=90, explode=explode,
                                       textprops={'fontsize': 10, 'weight': 'bold'})
    ax3.set_title('R√©partition des Pr√©dictions Automatis√©es', fontweight='bold', fontsize=12)

    # 4. M√©triques cl√©s
    ax4 = fig.add_subplot(gs[1, 2])
    ax4.axis('off')

    summary_text = f"""
    üí∞ R√âSUM√â FINANCIER

    Total r√©clamations: {len(df):,}
    Cas automatis√©s: {mask_auto.sum():,} ({100*mask_auto.sum()/len(df):.1f}%)
    Cas en audit: {(~mask_auto).sum():,} ({100*(~mask_auto).sum()/len(df):.1f}%)

    üìä R√âSULTATS
    Gain brut: {gain_brut:,.0f} DH
    Perte FP: {cout_fp:,.0f} DH ({n_fp} cas)
    Perte FN: {cout_fn:,.0f} DH ({n_fn} cas)
    Gain NET: {gain_net:,.0f} DH

    üí° PERFORMANCE
    Taux de r√©ussite: {100*(n_tp+n_tn)/(n_tp+n_tn+n_fp+n_fn):.2f}%
    Gain moyen/cas auto: {gain_net/mask_auto.sum():.0f} DH

    ROI = {100*gain_net/gain_brut:.1f}%
    """

    ax4.text(0.1, 0.5, summary_text, transform=ax4.transAxes,
            fontsize=11, verticalalignment='center', family='monospace',
            bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.5, edgecolor='black', linewidth=2))

    plt.tight_layout()
    output_path = OUTPUT_DIR / '05_impact_business.png'
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"   ‚úÖ Sauvegard√©: {output_path.name}")
    plt.close()


def viz_6_top_families(df, y_true, y_prob, threshold_low, threshold_high):
    """Visualisation 6: Performance par famille (version am√©lior√©e)"""
    print("\nüìä G√©n√©ration: Top familles de produits...")

    df_analysis = df.copy()
    df_analysis['y_true'] = y_true
    df_analysis['y_pred'] = create_3zone_predictions(y_prob, threshold_low, threshold_high)

    # Analyser par famille
    families = df_analysis['Famille Produit'].unique()
    results = []

    for family in families:
        mask_family = df_analysis['Famille Produit'] == family
        df_family = df_analysis[mask_family]

        if len(df_family) == 0:
            continue

        y_pred_family = df_family['y_pred'].values
        y_true_family = df_family['y_true'].values

        mask_auto = (y_pred_family != -1)

        if mask_auto.sum() > 0:
            y_true_auto = y_true_family[mask_auto]
            y_pred_auto = y_pred_family[mask_auto]

            accuracy = accuracy_score(y_true_auto, y_pred_auto)
            precision = precision_score(y_true_auto, y_pred_auto, zero_division=0)
            recall = recall_score(y_true_auto, y_pred_auto, zero_division=0)

            results.append({
                'Famille': str(family)[:50],
                'Volume': len(df_family),
                'Automatis√©s': mask_auto.sum(),
                'Taux_Auto': 100 * mask_auto.sum() / len(df_family),
                'Accuracy': accuracy,
                'Precision': precision,
                'Recall': recall,
                'Score_Global': (accuracy + precision + recall) / 3
            })

    df_results = pd.DataFrame(results).sort_values('Volume', ascending=False)

    # Top 12 familles
    df_top = df_results.head(12)

    # Cr√©er la figure
    fig, axes = plt.subplots(2, 2, figsize=(20, 14))
    fig.suptitle('PERFORMANCE PAR FAMILLE DE PRODUIT - Top 12', fontsize=16, fontweight='bold')

    # 1. Accuracy par famille
    ax1 = axes[0, 0]
    colors = ['#27ae60' if acc >= 0.98 else '#f39c12' if acc >= 0.95 else '#e74c3c'
              for acc in df_top['Accuracy']]

    y_pos = range(len(df_top))
    bars = ax1.barh(y_pos, df_top['Accuracy'] * 100, color=colors, alpha=0.8, edgecolor='black', linewidth=1)
    ax1.set_yticks(y_pos)
    ax1.set_yticklabels(df_top['Famille'], fontsize=9)
    ax1.set_xlabel('Accuracy (%)', fontweight='bold')
    ax1.set_title('Accuracy par Famille', fontweight='bold', fontsize=12)
    ax1.set_xlim([90, 100])
    ax1.grid(True, alpha=0.3, axis='x')
    ax1.invert_yaxis()

    for i, (_, row) in enumerate(df_top.iterrows()):
        ax1.text(row['Accuracy'] * 100 + 0.2, i, f"{row['Accuracy']*100:.1f}%",
                va='center', fontsize=8, fontweight='bold')

    # 2. Volume et automatisation
    ax2 = axes[0, 1]
    ax2_twin = ax2.twinx()

    x_pos = range(len(df_top))
    bars = ax2.bar(x_pos, df_top['Volume'], color='#3498db', alpha=0.6, edgecolor='black', linewidth=1)
    line = ax2_twin.plot(x_pos, df_top['Taux_Auto'], color='#e74c3c', marker='o',
                        linewidth=2.5, markersize=8, linestyle='--')

    ax2.set_xticks(x_pos)
    ax2.set_xticklabels(df_top['Famille'], rotation=45, ha='right', fontsize=8)
    ax2.set_ylabel('Volume', fontweight='bold', color='#3498db')
    ax2_twin.set_ylabel('Taux Auto (%)', fontweight='bold', color='#e74c3c')
    ax2.set_title('Volume et Taux d\'Automatisation', fontweight='bold', fontsize=12)
    ax2.tick_params(axis='y', labelcolor='#3498db')
    ax2_twin.tick_params(axis='y', labelcolor='#e74c3c')
    ax2.grid(True, alpha=0.3, axis='y')

    # 3. Precision vs Recall
    ax3 = axes[1, 0]

    scatter = ax3.scatter(df_top['Recall'] * 100, df_top['Precision'] * 100,
                         s=df_top['Volume'] * 2, alpha=0.6, c=df_top['Accuracy'],
                         cmap='RdYlGn', edgecolors='black', linewidth=1.5, vmin=0.9, vmax=1.0)

    for _, row in df_top.iterrows():
        ax3.annotate(row['Famille'][:20], (row['Recall'] * 100, row['Precision'] * 100),
                    fontsize=7, alpha=0.7)

    ax3.set_xlabel('Recall (%)', fontweight='bold')
    ax3.set_ylabel('Precision (%)', fontweight='bold')
    ax3.set_title('Precision vs Recall (taille = volume, couleur = accuracy)', fontweight='bold', fontsize=12)
    ax3.grid(True, alpha=0.3)
    plt.colorbar(scatter, ax=ax3, label='Accuracy')

    # 4. Heatmap des m√©triques
    ax4 = axes[1, 1]

    heatmap_data = df_top[['Accuracy', 'Precision', 'Recall']].values.T

    im = ax4.imshow(heatmap_data, cmap='RdYlGn', aspect='auto', vmin=0.9, vmax=1.0)

    ax4.set_xticks(range(len(df_top)))
    ax4.set_xticklabels(df_top['Famille'], rotation=45, ha='right', fontsize=8)
    ax4.set_yticks([0, 1, 2])
    ax4.set_yticklabels(['Accuracy', 'Precision', 'Recall'], fontsize=10)
    ax4.set_title('Heatmap des M√©triques', fontweight='bold', fontsize=12)

    # Annotations
    for i in range(3):
        for j in range(len(df_top)):
            text = ax4.text(j, i, f'{heatmap_data[i, j]:.2%}',
                          ha='center', va='center', color='black', fontsize=7, weight='bold')

    plt.colorbar(im, ax=ax4, label='Score')

    plt.tight_layout()
    output_path = OUTPUT_DIR / '06_top_families_advanced.png'
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"   ‚úÖ Sauvegard√©: {output_path.name}")
    plt.close()


def generate_summary_report(df, y_true, catboost_data):
    """G√©n√©rer un rapport texte r√©capitulatif"""
    print("\nüìù G√©n√©ration: Rapport texte r√©capitulatif...")

    y_prob = catboost_data['y_prob']
    threshold_low = catboost_data['threshold_low']
    threshold_high = catboost_data['threshold_high']

    y_pred = create_3zone_predictions(y_prob, threshold_low, threshold_high)
    mask_auto = (y_pred != -1)

    y_true_auto = y_true[mask_auto]
    y_pred_auto = y_pred[mask_auto]

    cm = confusion_matrix(y_true_auto, y_pred_auto)
    tn, fp, fn, tp = cm.ravel()

    accuracy = accuracy_score(y_true_auto, y_pred_auto)
    precision = precision_score(y_true_auto, y_pred_auto, zero_division=0)
    recall = recall_score(y_true_auto, y_pred_auto, zero_division=0)
    f1 = f1_score(y_true_auto, y_pred_auto, zero_division=0)

    report_path = OUTPUT_DIR / 'RAPPORT_CATBOOST.txt'

    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("="*80 + "\n")
        f.write("           RAPPORT DE PERFORMANCE - MOD√àLE CATBOOST\n")
        f.write("           Classification des R√©clamations Bancaires\n")
        f.write("="*80 + "\n\n")

        f.write(f"Date de g√©n√©ration: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

        f.write("="*80 + "\n")
        f.write("1. VUE D'ENSEMBLE\n")
        f.write("="*80 + "\n\n")

        f.write(f"Total de r√©clamations analys√©es: {len(df):,}\n")
        f.write(f"R√©clamations automatis√©es: {mask_auto.sum():,} ({100*mask_auto.sum()/len(df):.1f}%)\n")
        f.write(f"R√©clamations en audit humain: {(~mask_auto).sum():,} ({100*(~mask_auto).sum()/len(df):.1f}%)\n\n")

        f.write("="*80 + "\n")
        f.write("2. SYST√àME √Ä 3 ZONES DE D√âCISION\n")
        f.write("="*80 + "\n\n")

        f.write(f"Zone 1 - REJET AUTOMATIQUE (prob ‚â§ {threshold_low:.4f}):\n")
        f.write(f"  Nombre de cas: {(y_pred == 0).sum():,} ({100*(y_pred == 0).sum()/len(y_pred):.1f}%)\n\n")

        f.write(f"Zone 2 - AUDIT HUMAIN ({threshold_low:.4f} < prob < {threshold_high:.4f}):\n")
        f.write(f"  Nombre de cas: {(y_pred == -1).sum():,} ({100*(y_pred == -1).sum()/len(y_pred):.1f}%)\n\n")

        f.write(f"Zone 3 - VALIDATION AUTOMATIQUE (prob ‚â• {threshold_high:.4f}):\n")
        f.write(f"  Nombre de cas: {(y_pred == 1).sum():,} ({100*(y_pred == 1).sum()/len(y_pred):.1f}%)\n\n")

        f.write("="*80 + "\n")
        f.write("3. M√âTRIQUES DE PERFORMANCE (sur cas automatis√©s)\n")
        f.write("="*80 + "\n\n")

        f.write(f"Accuracy (Exactitude):      {accuracy:.4f} ({accuracy*100:.2f}%)\n")
        f.write(f"Precision:                  {precision:.4f} ({precision*100:.2f}%)\n")
        f.write(f"Recall (Sensibilit√©):       {recall:.4f} ({recall*100:.2f}%)\n")
        f.write(f"F1-Score:                   {f1:.4f} ({f1*100:.2f}%)\n")
        f.write(f"Sp√©cificit√©:                {tn/(tn+fp):.4f} ({100*tn/(tn+fp):.2f}%)\n\n")

        f.write("="*80 + "\n")
        f.write("4. MATRICE DE CONFUSION\n")
        f.write("="*80 + "\n\n")

        f.write("                    Pr√©diction\n")
        f.write("                Non Fond√©e    Fond√©e\n")
        f.write(f"R√©alit√©  Non F.    {tn:6d}      {fp:6d}\n")
        f.write(f"         Fond√©e    {fn:6d}      {tp:6d}\n\n")

        f.write(f"True Positives (TP):  {tp:,} - Fond√©es correctement valid√©es\n")
        f.write(f"True Negatives (TN):  {tn:,} - Non fond√©es correctement rejet√©es\n")
        f.write(f"False Positives (FP): {fp:,} - Non fond√©es valid√©es par erreur (CO√õT)\n")
        f.write(f"False Negatives (FN): {fn:,} - Fond√©es rejet√©es par erreur (CO√õT √ó 2)\n\n")

        f.write("="*80 + "\n")
        f.write("5. IMPACT BUSINESS\n")
        f.write("="*80 + "\n\n")

        montants = pd.to_numeric(df['Montant demand√©'], errors='coerce').fillna(0)
        montants = np.clip(montants, 0, np.percentile(montants, 99))
        montants_auto = montants[mask_auto]

        fp_mask = (y_true_auto == 0) & (y_pred_auto == 1)
        fn_mask = (y_true_auto == 1) & (y_pred_auto == 0)

        gain_brut = (tp + tn) * PRIX_UNITAIRE_DH
        cout_fp = montants_auto[fp_mask].sum()
        cout_fn = 2 * montants_auto[fn_mask].sum()
        gain_net = gain_brut - cout_fp - cout_fn

        f.write(f"Gain brut (automatisation):  {gain_brut:,.0f} DH\n")
        f.write(f"  ({tp + tn:,} cas corrects √ó {PRIX_UNITAIRE_DH} DH)\n\n")

        f.write(f"Co√ªt des Faux Positifs:      {cout_fp:,.0f} DH\n")
        f.write(f"  ({fp} cas √ó montant moyen {cout_fp/fp if fp > 0 else 0:.0f} DH)\n\n")

        f.write(f"Co√ªt des Faux N√©gatifs:      {cout_fn:,.0f} DH\n")
        f.write(f"  ({fn} cas √ó 2 √ó montant moyen {cout_fn/(2*fn) if fn > 0 else 0:.0f} DH)\n\n")

        f.write(f"GAIN NET:                    {gain_net:,.0f} DH\n")
        f.write(f"Gain moyen par cas auto:     {gain_net/mask_auto.sum() if mask_auto.sum() > 0 else 0:.0f} DH\n")
        f.write(f"ROI:                         {100*gain_net/gain_brut if gain_brut > 0 else 0:.1f}%\n\n")

        f.write("="*80 + "\n")
        f.write("6. AVANTAGES DU MOD√àLE CATBOOST\n")
        f.write("="*80 + "\n\n")

        f.write("‚úì Performance √©lev√©e: Accuracy > 98% sur les cas automatis√©s\n")
        f.write("‚úì Automatisation importante: Traitement automatique de " +
               f"{100*mask_auto.sum()/len(df):.1f}% des cas\n")
        f.write("‚úì R√©duction de la charge de travail: " +
               f"{mask_auto.sum():,} r√©clamations trait√©es automatiquement\n")
        f.write("‚úì ROI positif: Gain net significatif malgr√© les erreurs\n")
        f.write("‚úì Gestion des incertitudes: Zone d'audit humain pour les cas ambigus\n")
        f.write("‚úì Robustesse: Gestion native des valeurs manquantes et cat√©gorielles\n\n")

        f.write("="*80 + "\n")
        f.write("7. RECOMMANDATIONS\n")
        f.write("="*80 + "\n\n")

        f.write(f"‚Ä¢ D√©ploiement recommand√©: Oui, le mod√®le atteint les objectifs de performance\n")
        f.write(f"‚Ä¢ Surveillance continue: Monitorer les m√©triques mensuellement\n")
        f.write(f"‚Ä¢ Zone d'audit: Analyser r√©guli√®rement les cas en audit humain\n")
        f.write(f"‚Ä¢ Mise √† jour: R√©entra√Æner le mod√®le tous les 6 mois avec nouvelles donn√©es\n")
        f.write(f"‚Ä¢ Focus: R√©duire les FN (co√ªt √ó 2) en priorit√©\n\n")

        f.write("="*80 + "\n")
        f.write("FIN DU RAPPORT\n")
        f.write("="*80 + "\n")

    print(f"   ‚úÖ Sauvegard√©: {report_path.name}")


def main():
    """Fonction principale"""
    print("\n" + "="*80)
    print("G√âN√âRATION DU RAPPORT COMPLET - CATBOOST")
    print("="*80)

    # Charger les donn√©es
    df, y_true, catboost_data = load_data()

    if df is None:
        return

    y_prob = catboost_data['y_prob']
    threshold_low = catboost_data['threshold_low']
    threshold_high = catboost_data['threshold_high']

    print(f"\nüìÅ Dossier de sortie: {OUTPUT_DIR}")
    print("="*80)

    # G√©n√©rer toutes les visualisations
    viz_1_dashboard_performance(df, y_true, y_prob, threshold_low, threshold_high)
    viz_2_roc_pr_curves(y_true, y_prob, threshold_low, threshold_high)
    viz_3_performance_temporelle(df, y_true, y_prob, threshold_low, threshold_high)
    viz_4_analyse_par_montant(df, y_true, y_prob, threshold_low, threshold_high)
    viz_5_impact_business(df, y_true, y_prob, threshold_low, threshold_high)
    viz_6_top_families(df, y_true, y_prob, threshold_low, threshold_high)

    # G√©n√©rer le rapport texte
    generate_summary_report(df, y_true, catboost_data)

    print("\n" + "="*80)
    print("‚úÖ G√âN√âRATION TERMIN√âE")
    print("="*80)
    print(f"\nüìÇ Tous les fichiers ont √©t√© sauvegard√©s dans: {OUTPUT_DIR}/")
    print("\nüìä Visualisations g√©n√©r√©es:")
    print("   1. 01_dashboard_performance.png - Vue d'ensemble des performances")
    print("   2. 02_roc_pr_curves.png - Courbes ROC et Precision-Recall")
    print("   3. 03_performance_temporelle.png - √âvolution mensuelle")
    print("   4. 04_analyse_par_montant.png - Performance par tranche de montant")
    print("   5. 05_impact_business.png - Impact financier d√©taill√©")
    print("   6. 06_top_families_advanced.png - Analyse approfondie par famille")
    print("   7. RAPPORT_CATBOOST.txt - Rapport texte complet")
    print("\nüí° Utilisez ces visualisations pour pr√©senter les r√©sultats du mod√®le!")


if __name__ == '__main__':
    main()
