# üè¶ Pipeline ML Production - Classification des R√©clamations Bancaires

## üìã Vue d'Ensemble

Pipeline complet de Machine Learning pour la classification des r√©clamations bancaires (Fond√©e / Non Fond√©e) avec validation temporelle et d√©tection de drift.

### ‚ú® Caract√©ristiques Principales

- ‚úÖ **Preprocessing Robuste** : Feature engineering avanc√© avec 15+ features cr√©√©s
- ‚úÖ **S√©lection de Features** : Multi-crit√®res (variance, corr√©lation, importance)
- ‚úÖ **Optimisation Optuna** : XGBoost/LightGBM/CatBoost avec 50+ trials
- ‚úÖ **Calibration des Probabilit√©s** : M√©thodes isotonic/sigmoid
- ‚úÖ **Validation Temporelle** : Test sur donn√©es 2025 (futures)
- ‚úÖ **Analyse de Drift** : Tests statistiques KS et Chi¬≤
- ‚úÖ **Rapports Complets** : M√©triques, visualisations, recommandations



## üìÅ Structure du Projet

```
ml_pipeline/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                    # Donn√©es brutes 2024 et 2025
‚îÇ   ‚îî‚îÄ‚îÄ processed/              # Donn√©es transform√©es
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ preprocessor.py     # Feature engineering + encodage
‚îÇ   ‚îú‚îÄ‚îÄ feature_selection/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ selector.py         # S√©lection multi-crit√®res
‚îÇ   ‚îú‚îÄ‚îÄ modeling/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ optuna_optimizer.py # Optimisation hyperparam√®tres
‚îÇ   ‚îú‚îÄ‚îÄ evaluation/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ calibrator.py       # Calibration probabilit√©s
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metrics.py          # Calcul m√©triques
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ drift_analyzer.py   # D√©tection drift
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îî‚îÄ‚îÄ data_generator.py   # G√©n√©ration donn√©es synth√©tiques
‚îÇ
‚îú‚îÄ‚îÄ outputs/
‚îÇ   ‚îú‚îÄ‚îÄ models/                 # Mod√®les sauvegard√©s
‚îÇ   ‚îú‚îÄ‚îÄ preprocessors/          # Transformers sauvegard√©s
‚îÇ   ‚îî‚îÄ‚îÄ reports/                # Rapports et visualisations
‚îÇ
‚îú‚îÄ‚îÄ main_pipeline.py            # Pipeline principal
‚îú‚îÄ‚îÄ requirements.txt            # D√©pendances
‚îî‚îÄ‚îÄ README.md                   # Ce fichier
```

## üöÄ Installation

### Pr√©requis
- Python 3.8+
- 8 GB RAM minimum

### Installation des D√©pendances

```bash
pip install -r requirements.txt
```

**D√©pendances principales:**
- pandas, numpy, scipy
- scikit-learn
- xgboost, lightgbm, catboost
- optuna
- matplotlib, seaborn
- openpyxl (pour Excel)
- shap (optionnel, pour explainability)

## üé¨ Utilisation



### 1. Ex√©cution du Pipeline Complet

```bash
python main_pipeline.py
```

**Dur√©e estim√©e:** 10-15 minutes (avec 50 trials Optuna)

### 2. Configuration Personnalis√©e

√âditez le bloc `config` dans `main_pipeline.py` :

```python
config = {
    'data_path_2024': 'data/raw/reclamations_2024.xlsx',
    'data_path_2025': 'data/raw/reclamations_2025.xlsx',
    'optuna_trials': 100,        # Nombre de trials (50-200)
    'cv_folds': 5,               # Nombre de folds CV
    'model_type': 'xgboost',     # xgboost, lightgbm, catboost
    'calibration_method': 'isotonic',  # isotonic ou sigmoid
    'random_state': 42
}
```

## üìä Sorties G√©n√©r√©es

### Mod√®les et Artefacts

```
outputs/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ model_xgboost_20260111.pkl          # Mod√®le entra√Æn√©
‚îÇ   ‚îú‚îÄ‚îÄ best_hyperparameters.json           # Hyperparam√®tres optimaux
‚îÇ   ‚îî‚îÄ‚îÄ metadata_20260111.json              # M√©tadonn√©es compl√®tes
‚îÇ
‚îú‚îÄ‚îÄ preprocessors/
‚îÇ   ‚îú‚îÄ‚îÄ preprocessor.pkl                    # Pipeline preprocessing
‚îÇ   ‚îî‚îÄ‚îÄ feature_selector.pkl                # S√©lecteur de features
‚îÇ
‚îî‚îÄ‚îÄ reports/
    ‚îú‚îÄ‚îÄ RAPPORT_FINAL.txt                   # üìÑ RAPPORT COMPLET
    ‚îú‚îÄ‚îÄ feature_importance.csv              # Importance des features
    ‚îú‚îÄ‚îÄ optuna_history.csv                  # Historique optimisation
    ‚îú‚îÄ‚îÄ metrics_2024.json                   # M√©triques 2024
    ‚îú‚îÄ‚îÄ metrics_2025.json                   # M√©triques 2025
    ‚îú‚îÄ‚îÄ drift_report_numerical.csv          # Rapport drift num√©riques
    ‚îú‚îÄ‚îÄ drift_report_categorical.csv        # Rapport drift cat√©gorielles
    ‚îî‚îÄ‚îÄ figures/
        ‚îú‚îÄ‚îÄ confusion_matrix_2024.png       # Confusion 2024
        ‚îú‚îÄ‚îÄ confusion_matrix_2025.png       # Confusion 2025
        ‚îú‚îÄ‚îÄ roc_curve_2024.png              # ROC 2024
        ‚îú‚îÄ‚îÄ roc_curve_2025.png              # ROC 2025
        ‚îú‚îÄ‚îÄ pr_curve_2024.png               # Precision-Recall 2024
        ‚îú‚îÄ‚îÄ pr_curve_2025.png               # Precision-Recall 2025
        ‚îú‚îÄ‚îÄ calibration_curve.png           # Calibration
        ‚îî‚îÄ‚îÄ prob_distribution_comparison.png # Comparaison pr√©dictions
```

## üîß Modules D√©taill√©s

### 1. Preprocessing (`src/preprocessing/preprocessor.py`)

**Features Engineering:**
- Ratios : `ratio_pnb_montant`, `ratio_montant_famille`
- Temporels : `mois`, `trimestre`, `jour_semaine`, `est_weekend`
- Agr√©gations : `ratio_produits_anciennete`, `taux_reclamations_annuel`
- Flags : `is_high_value`, `is_frequent_claimer`, `is_senior`
- Interactions : `montant_x_anciennete`, `pnb_x_segment`
- Log-transform : `log_montant`, `log_pnb`, `log_anciennete`

**Encodage:**
- Target Encoding avec smoothing (√©vite overfitting)
- Traitement des outliers (IQR clipping)
- Standardisation robuste (RobustScaler)

### 2. S√©lection de Features (`src/feature_selection/selector.py`)

**Crit√®res d'√©limination:**
1. ‚ùå Features avec >50% de valeurs manquantes
2. ‚ùå Features √† variance quasi-nulle (< 0.01)
3. ‚ùå Features corr√©l√©es >0.95
4. ‚ùå Features √† faible importance (consensus de 2+ m√©thodes)

**M√©thodes d'importance:**
- Permutation Importance
- Native Feature Importance (Random Forest)
- SHAP values (optionnel)

### 3. Optimisation Optuna (`src/modeling/optuna_optimizer.py`)

**Hyperparam√®tres optimis√©s:**
- `max_depth` : [3, 10]
- `learning_rate` : [0.01, 0.3] (log scale)
- `n_estimators` : [100, 1000]
- `subsample` : [0.6, 1.0]
- `colsample_bytree` : [0.6, 1.0]
- `reg_alpha` (L1) : [1e-8, 10] (log scale)
- `reg_lambda` (L2) : [1e-8, 10] (log scale)
- `scale_pos_weight` : calcul√© automatiquement

**Strat√©gie:**
- TPESampler (Tree-structured Parzen Estimator)
- MedianPruner (arr√™t pr√©coce des mauvais trials)
- Validation crois√©e StratifiedKFold 5-fold
- M√©trique d'optimisation : F1-Score

### 4. Calibration (`src/evaluation/calibrator.py`)

**M√©thodes:**
- Isotonic Regression (non-param√©trique)
- Sigmoid (param√©trique)

**M√©triques de calibration:**
- Expected Calibration Error (ECE)
- Brier Score

### 5. Analyse de Drift (`src/evaluation/drift_analyzer.py`)

**Tests statistiques:**
- **Kolmogorov-Smirnov** : features num√©riques
- **Chi¬≤** : features cat√©gorielles

**Seuil de signification:** p < 0.05

## üìà Top Features Importantes

1. **Categorie_encoded** (1.0000) - Type de r√©clamation
2. **Famille_Produit_encoded** (0.5391) - Famille produit
3. **log_montant** (0.2295) - Log du montant demand√©
4. **montant_x_anciennete** (0.2098) - Interaction
5. **ratio_montant_famille** (0.1894) - Ratio montant/m√©diane famille

## üîç Analyse des R√©sultats

### Pourquoi la d√©gradation sur 2025 ?

**Causes identifi√©es:**

1. **Drift temporel intentionnel** dans les donn√©es g√©n√©r√©es:
   - Taux de r√©clamations fond√©es : 53.5% ‚Üí 49.1% (-8.1%)
   - Montant moyen : +15.1%
   - PNB moyen : +19.4%

2. **Distribution changeante des classes:**
   - Le mod√®le a appris sur une distribution 2024
   - La distribution 2025 est significativement diff√©rente

3. **Concept drift:**
   - Les crit√®res de fondement peuvent avoir √©volu√©
   - Les comportements clients changent

### Solutions Recommand√©es

‚úÖ **Solution 1: R√©entra√Ænement**
- R√©entra√Æner sur donn√©es combin√©es 2024 + 2025
- Validation crois√©e temporelle

‚úÖ **Solution 2: Apprentissage Continu**
- R√©entra√Ænement mensuel/trimestriel
- Monitoring du drift en production
- Alertes automatiques

‚úÖ **Solution 3: Mod√®les Adaptatifs**
- Online learning
- Ensemble avec poids temporels

## üö® Monitoring en Production

**KPIs √† suivre:**
- Accuracy, F1-Score hebdomadaire
- Distribution des probabilit√©s pr√©dites
- Tests de drift mensuels
- Temps de r√©ponse

**Seuils d'alerte:**
- D√©gradation > 5% : ‚ö†Ô∏è Warning
- D√©gradation > 10% : üö® Critical
- Drift d√©tect√© (p < 0.05) : üîî Investigation

## üéì M√©thodologie

### Points Forts

‚úÖ Validation temporelle (train 2024, test 2025)
‚úÖ Feature engineering robuste (15+ features)
‚úÖ Optimisation bay√©sienne (Optuna)
‚úÖ Calibration des probabilit√©s
‚úÖ D√©tection de drift automatique
‚úÖ M√©triques compl√®tes
‚úÖ Reproductibilit√© (random_state fix√©)

### Limites

‚ö†Ô∏è Pas de validation sur donn√©es r√©elles (synth√©tiques)
‚ö†Ô∏è Drift intentionnel tr√®s prononc√© (d√©monstration)
‚ö†Ô∏è Pas d'ensemble de mod√®les
‚ö†Ô∏è Pas de SHAP pour explainability d√©taill√©e

## üìù Licence

MIT License

## üë• Auteur

Pipeline d√©velopp√© pour d√©monstration de best practices ML en production.

---

**Version:** 1.0.0
**Date:** Janvier 2026
**Statut:** ‚úÖ Complet et Fonctionnel
