"""
COMPARAISON DE MOD√àLES V2 - Features Production-Ready
XGBoost vs Random Forest vs CatBoost
Entra√Ænement sur 2024, Test sur 2025

Utilise uniquement des features disponibles en temps r√©el
"""
import sys
sys.path.append('src')

import pandas as pd
import numpy as np
import joblib
from pathlib import Path
from datetime import datetime
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
from catboost import CatBoostClassifier
import optuna
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

# Import du preprocessor V2
from preprocessor_v2 import ProductionPreprocessorV2

# Configuration
sns.set_style('whitegrid')
plt.rcParams['figure.figsize'] = (16, 10)

PRIX_UNITAIRE_DH = 169


class ModelComparisonV2:
    """Comparaison de 3 mod√®les avec features production-ready"""

    def __init__(self, min_samples_stats=30):
        self.models = {}
        self.results = {}
        self.preprocessor = ProductionPreprocessorV2(min_samples_stats=min_samples_stats)

    def load_data(self):
        """Charger donn√©es 2024 et 2025"""
        print("\n" + "="*80)
        print("üìÇ CHARGEMENT DES DONN√âES")
        print("="*80)

        self.df_2024 = pd.read_excel('data/raw/reclamations_2024.xlsx')
        self.df_2025 = pd.read_excel('data/raw/reclamations_2025.xlsx')

        print(f"‚úÖ 2024: {len(self.df_2024)} r√©clamations")
        print(f"‚úÖ 2025: {len(self.df_2025)} r√©clamations")

        # V√©rifier les colonnes n√©cessaires
        required_cols = ['Montant demand√©', 'Famille Produit', 'Fondee']
        for col in required_cols:
            if col not in self.df_2024.columns:
                raise ValueError(f"Colonne manquante dans 2024: {col}")
            if col not in self.df_2025.columns and col != 'Fondee':
                raise ValueError(f"Colonne manquante dans 2025: {col}")

    def prepare_data(self):
        """Preprocessing"""
        print("\n" + "="*80)
        print("üîß PREPROCESSING V2 - Features Production-Ready")
        print("="*80)

        # Fit sur 2024 (avec Fondee pour calculer les taux)
        X_train = self.preprocessor.fit_transform(self.df_2024)
        y_train = self.df_2024['Fondee'].values

        # Transform sur 2025 (utilise les stats de 2024)
        X_test = self.preprocessor.transform(self.df_2025)
        y_test = self.df_2025['Fondee'].values

        print(f"\nüìä Shape 2024: {X_train.shape}")
        print(f"üìä Shape 2025: {X_test.shape}")

        # Afficher info sur les features
        info = self.preprocessor.get_feature_info()
        print(f"\nüìã Statistiques calcul√©es sur 2024:")
        print(f"   Familles avec stats robustes: {info['family_stats_count']}")
        print(f"   Cat√©gories avec stats robustes: {info['category_stats_count']}")
        print(f"   Sous-cat√©gories avec stats robustes: {info['subcategory_stats_count']}")
        print(f"   Segments avec stats robustes: {info['segment_stats_count']}")
        print(f"   (Minimum {info['min_samples_for_stats']} cas pour √™tre consid√©r√© robuste)")

        self.X_train = X_train
        self.y_train = y_train
        self.X_test = X_test
        self.y_test = y_test

    def optimize_catboost(self):
        """Optimiser CatBoost avec Optuna"""
        print("\nüî¨ Optimisation CatBoost...")

        def objective(trial):
            params = {
                'iterations': trial.suggest_int('iterations', 100, 500),
                'depth': trial.suggest_int('depth', 4, 10),
                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-8, 10.0, log=True),
                'border_count': trial.suggest_int('border_count', 32, 255),
            }

            model = CatBoostClassifier(**params, random_state=42, verbose=0)
            cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
            scores = cross_val_score(model, self.X_train, self.y_train, cv=cv, scoring='f1', n_jobs=-1)

            return scores.mean()

        study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=42))
        study.optimize(objective, n_trials=50, show_progress_bar=False)

        best_params = study.best_params
        print(f"   ‚úÖ Best F1-Score CV: {study.best_value:.4f}")

        model = CatBoostClassifier(**best_params, random_state=42, verbose=0)
        model.fit(self.X_train, self.y_train)

        return model

    def optimize_xgboost(self):
        """Optimiser XGBoost avec Optuna"""
        print("\nüî¨ Optimisation XGBoost...")

        def objective(trial):
            params = {
                'n_estimators': trial.suggest_int('n_estimators', 100, 500),
                'max_depth': trial.suggest_int('max_depth', 3, 10),
                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
                'subsample': trial.suggest_float('subsample', 0.6, 1.0),
                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
                'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),
                'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),
            }

            model = xgb.XGBClassifier(**params, random_state=42, n_jobs=-1, eval_metric='logloss')
            cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
            scores = cross_val_score(model, self.X_train, self.y_train, cv=cv, scoring='f1', n_jobs=-1)

            return scores.mean()

        study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=42))
        study.optimize(objective, n_trials=50, show_progress_bar=False)

        best_params = study.best_params
        print(f"   ‚úÖ Best F1-Score CV: {study.best_value:.4f}")

        model = xgb.XGBClassifier(**best_params, random_state=42, n_jobs=-1, eval_metric='logloss')
        model.fit(self.X_train, self.y_train)

        return model

    def train_models(self):
        """Entra√Æner XGBoost et CatBoost pour comparaison"""
        print("\n" + "="*80)
        print("üéØ ENTRA√éNEMENT DES MOD√àLES")
        print("="*80)

        self.models['XGBoost'] = self.optimize_xgboost()

        try:
            self.models['CatBoost'] = self.optimize_catboost()
            print("\n‚úÖ Mod√®les entra√Æn√©s: XGBoost, CatBoost")
        except AttributeError as e:
            if '__sklearn_tags__' in str(e):
                print("\n‚ö†Ô∏è CatBoost sklearn compatibility issue - continuing with XGBoost only")
                print("\n‚úÖ Mod√®le entra√Æn√©: XGBoost")
            else:
                raise

    def optimize_threshold_dual(self, y_prob, name):
        """Optimiser 2 seuils pour cr√©er 3 zones avec taux d'automatisation √©lev√©"""
        print(f"\nüéØ Optimisation des seuils de d√©cision (3 zones - taux automatisation √©lev√©)...")

        montants_2025 = self.df_2025['Montant demand√©'].values
        best_result = None
        best_gain_net = -float('inf')
        best_result_relaxed = None
        best_score_relaxed = -float('inf')
        threshold_results = []

        # Tester diff√©rentes combinaisons de seuils (plages √©largies pour + d'automatisation)
        for t_low in np.arange(0.05, 0.50, 0.02):  # Commence √† 0.05 au lieu de 0.10
            for t_high in np.arange(0.50, 0.98, 0.02):  # Va jusqu'√† 0.98 au lieu de 0.95
                if t_high <= t_low:
                    continue

                # 3 zones
                mask_rejet = y_prob <= t_low
                mask_audit = (y_prob > t_low) & (y_prob < t_high)
                mask_validation = y_prob >= t_high

                # Pr√©dictions
                y_pred = np.zeros(len(y_prob), dtype=int)
                y_pred[mask_validation] = 1

                # Cas automatis√©s
                mask_auto = mask_rejet | mask_validation

                if mask_auto.sum() == 0:
                    continue

                # M√©triques
                y_pred_auto = y_pred[mask_auto]
                y_true_auto = self.y_test[mask_auto]
                montants_auto = montants_2025[mask_auto]

                fp_mask = (y_true_auto == 0) & (y_pred_auto == 1)
                fn_mask = (y_true_auto == 1) & (y_pred_auto == 0)

                # Calcul financier
                montants_auto_clean = np.nan_to_num(montants_auto, nan=0.0, posinf=0.0, neginf=0.0)
                if len(montants_auto_clean) > 0 and montants_auto_clean.max() > 0:
                    montants_auto_clean = np.clip(montants_auto_clean, 0, np.percentile(montants_auto_clean, 99))
                else:
                    montants_auto_clean = montants_auto_clean.clip(0)

                perte_fp = montants_auto_clean[fp_mask].sum()
                perte_fn = 2 * montants_auto_clean[fn_mask].sum()

                auto_count = mask_auto.sum()
                gain_brut = auto_count * PRIX_UNITAIRE_DH
                gain_net = gain_brut - perte_fp - perte_fn

                # Pr√©cisions par zone
                prec_rejet = (self.y_test[mask_rejet] == 0).mean() if mask_rejet.sum() > 0 else 0
                prec_validation = (self.y_test[mask_validation] == 1).mean() if mask_validation.sum() > 0 else 0

                automation_rate = mask_auto.sum() / len(y_prob)

                threshold_results.append({
                    'threshold_low': t_low,
                    'threshold_high': t_high,
                    'gain_net': gain_net,
                    'auto': auto_count,
                    'fp': fp_mask.sum(),
                    'fn': fn_mask.sum(),
                    'n_rejet': mask_rejet.sum(),
                    'n_audit': mask_audit.sum(),
                    'n_validation': mask_validation.sum(),
                    'prec_rejet': prec_rejet,
                    'prec_validation': prec_validation,
                    'automation_rate': automation_rate
                })

                # Crit√®re principal: Maximiser gain NET avec contraintes assouplies
                # (assouplies pour favoriser l'automatisation)
                if prec_rejet >= 0.93 and prec_validation >= 0.90:  # Assouplies de 0.95/0.93
                    if gain_net > best_gain_net:
                        best_gain_net = gain_net
                        best_result = threshold_results[-1].copy()

                # Crit√®re secondaire: Favoriser l'automatisation avec pr√©cisions minimales acceptables
                if prec_rejet >= 0.90 and prec_validation >= 0.87:
                    # Score composite: gain NET + bonus pour automatisation √©lev√©e
                    score = gain_net + (automation_rate * 100000)  # Bonus pour automatisation
                    if score > best_score_relaxed:
                        best_score_relaxed = score
                        best_result_relaxed = threshold_results[-1].copy()

        # Choisir le meilleur r√©sultat
        if best_result is None and best_result_relaxed is not None:
            best_result = best_result_relaxed
            print(f"   ‚ö†Ô∏è Utilisation crit√®re relaxed pour maximiser automatisation")
        elif best_result is None and threshold_results:
            # Fallback: meilleur compromis gain NET / automatisation
            best_result = max(threshold_results,
                            key=lambda x: x['gain_net'] + (x['automation_rate'] * 50000))
            print(f"   ‚ö†Ô∏è Utilisation du meilleur compromis gain NET / automatisation")

        if best_result:
            print(f"   ‚úÖ Seuil BAS (Rejet): {best_result['threshold_low']:.2f}")
            print(f"   ‚úÖ Seuil HAUT (Validation): {best_result['threshold_high']:.2f}")
            print(f"   ‚úÖ Taux automatisation: {best_result['automation_rate']:.1%}")
            print(f"   ‚úÖ Pr√©cision Rejet: {best_result['prec_rejet']:.1%}")
            print(f"   ‚úÖ Pr√©cision Validation: {best_result['prec_validation']:.1%}")
            print(f"   ‚úÖ Gain NET: {best_result['gain_net']:,.0f} DH")
        else:
            # Fallback ultime
            best_result = {
                'threshold_low': 0.3,
                'threshold_high': 0.7,
                'gain_net': 0,
                'auto': 0,
                'fp': 0,
                'fn': 0,
                'n_rejet': 0,
                'n_audit': len(y_prob),
                'n_validation': 0,
                'prec_rejet': 0,
                'prec_validation': 0,
                'automation_rate': 0
            }

        return best_result, threshold_results

    def evaluate_models(self):
        """√âvaluer sur 2025 avec optimisation des seuils"""
        print("\n" + "="*80)
        print("üìä √âVALUATION SUR 2025")
        print("="*80)

        for name, model in self.models.items():
            print(f"\n{'='*80}")
            print(f"üìä {name}")
            print(f"{'='*80}")

            # Probabilit√©s
            y_prob = model.predict_proba(self.X_test)[:, 1]

            # Optimisation des seuils
            best_thresholds, threshold_results = self.optimize_threshold_dual(y_prob, name)

            # Cr√©er les pr√©dictions
            t_low = best_thresholds['threshold_low']
            t_high = best_thresholds['threshold_high']

            y_pred = np.zeros(len(y_prob), dtype=int)
            mask_rejet = y_prob <= t_low
            mask_audit = (y_prob > t_low) & (y_prob < t_high)
            mask_validation = y_prob >= t_high
            y_pred[mask_validation] = 1

            # M√©triques
            mask_auto = mask_rejet | mask_validation
            if mask_auto.sum() > 0:
                y_pred_auto = y_pred[mask_auto]
                y_true_auto = self.y_test[mask_auto]

                acc = accuracy_score(y_true_auto, y_pred_auto)
                prec = precision_score(y_true_auto, y_pred_auto, zero_division=0)
                rec = recall_score(y_true_auto, y_pred_auto, zero_division=0)
                f1 = f1_score(y_true_auto, y_pred_auto, zero_division=0)
            else:
                acc = prec = rec = f1 = 0

            auc = roc_auc_score(self.y_test, y_prob)

            print(f"\nüìä M√©triques (sur cas automatis√©s):")
            print(f"   Accuracy   : {acc:.4f}")
            print(f"   Precision  : {prec:.4f}")
            print(f"   Recall     : {rec:.4f}")
            print(f"   F1-Score   : {f1:.4f}")
            print(f"   ROC-AUC    : {auc:.4f}")

            # Sauvegarder r√©sultats
            self.results[name] = {
                'threshold_low': t_low,
                'threshold_high': t_high,
                'accuracy': acc,
                'precision': prec,
                'recall': rec,
                'f1': f1,
                'auc': auc,
                'auto': best_thresholds['auto'],
                'gain_net': best_thresholds['gain_net'],
                'y_pred': y_pred,
                'y_prob': y_prob,
                'threshold_results': threshold_results
            }

    def save_models(self):
        """Sauvegarder les mod√®les et le preprocessor"""
        print("\nüíæ Sauvegarde des mod√®les...")

        output_dir = Path('outputs/production_v2/models')
        output_dir.mkdir(parents=True, exist_ok=True)

        # D√©terminer le meilleur mod√®le bas√© sur le gain NET
        best_model_name = max(self.results.items(), key=lambda x: x[1]['gain_net'])[0]
        print(f"\nüèÜ Meilleur mod√®le (gain NET): {best_model_name}")
        print(f"   Gain NET: {self.results[best_model_name]['gain_net']:,.0f} DH")
        print(f"   Taux automatisation: {self.results[best_model_name]['auto'] / len(self.y_test):.1%}")

        # Sauvegarder XGBoost
        if 'XGBoost' in self.models:
            xgb_path = output_dir / 'xgboost_model_v2.pkl'
            joblib.dump(self.models['XGBoost'], xgb_path)
            print(f"‚úÖ XGBoost sauvegard√©: {xgb_path}")

        # Sauvegarder CatBoost
        if 'CatBoost' in self.models:
            catboost_path = output_dir / 'catboost_model_v2.pkl'
            joblib.dump(self.models['CatBoost'], catboost_path)
            print(f"‚úÖ CatBoost sauvegard√©: {catboost_path}")

        # Sauvegarder le meilleur mod√®le sous un nom g√©n√©rique
        best_model_path = output_dir / 'best_model_v2.pkl'
        joblib.dump(self.models[best_model_name], best_model_path)
        print(f"‚úÖ Meilleur mod√®le sauvegard√©: {best_model_path}")

        # Sauvegarder info sur le meilleur mod√®le
        best_info_path = output_dir / 'best_model_info.txt'
        with open(best_info_path, 'w') as f:
            f.write(f"Meilleur mod√®le: {best_model_name}\n")
            f.write(f"Gain NET: {self.results[best_model_name]['gain_net']:,.0f} DH\n")
            f.write(f"Seuil BAS: {self.results[best_model_name]['threshold_low']:.4f}\n")
            f.write(f"Seuil HAUT: {self.results[best_model_name]['threshold_high']:.4f}\n")

        # Sauvegarder le preprocessor
        preprocessor_path = output_dir / 'preprocessor_v2.pkl'
        joblib.dump(self.preprocessor, preprocessor_path)
        print(f"‚úÖ Preprocessor V2 sauvegard√©: {preprocessor_path}")

        print(f"\nüìÇ Mod√®les disponibles pour l'inf√©rence dans: {output_dir}")

    def save_predictions(self):
        """Sauvegarder les pr√©dictions des deux mod√®les"""
        print("\nüíæ Sauvegarde des pr√©dictions...")

        output_dir = Path('outputs/production_v2/predictions')
        output_dir.mkdir(parents=True, exist_ok=True)

        # D√©terminer le meilleur mod√®le
        best_model_name = max(self.results.items(), key=lambda x: x[1]['gain_net'])[0]

        predictions_data = {
            'best_model': best_model_name,
            'y_true': self.y_test
        }

        # Ajouter XGBoost s'il existe
        if 'XGBoost' in self.results:
            predictions_data['XGBoost'] = {
                'y_pred': self.results['XGBoost']['y_pred'],
                'y_prob': self.results['XGBoost']['y_prob'],
                'threshold_low': self.results['XGBoost']['threshold_low'],
                'threshold_high': self.results['XGBoost']['threshold_high']
            }

        # Ajouter CatBoost s'il existe
        if 'CatBoost' in self.results:
            predictions_data['CatBoost'] = {
                'y_pred': self.results['CatBoost']['y_pred'],
                'y_prob': self.results['CatBoost']['y_prob'],
                'threshold_low': self.results['CatBoost']['threshold_low'],
                'threshold_high': self.results['CatBoost']['threshold_high']
            }

        predictions_path = output_dir / 'predictions_2025_v2.pkl'
        joblib.dump(predictions_data, predictions_path)

        print(f"‚úÖ Pr√©dictions sauvegard√©es: {predictions_path}")
        print(f"   Meilleur mod√®le: {best_model_name}")

    def generate_report(self):
        """G√©n√©rer rapport texte comparatif"""
        output_dir = Path('outputs/production_v2')
        output_dir.mkdir(parents=True, exist_ok=True)

        report_path = output_dir / 'rapport_v2.txt'

        # D√©terminer le meilleur mod√®le
        best_model_name = max(self.results.items(), key=lambda x: x[1]['gain_net'])[0]

        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("="*80 + "\n")
            f.write("RAPPORT COMPARAISON MOD√àLES V2 - FEATURES PRODUCTION-READY\n")
            f.write(f"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("="*80 + "\n\n")

            f.write("FEATURES UTILIS√âES:\n")
            f.write("- Uniquement des colonnes disponibles en temps r√©el\n")
            f.write("- Montant demand√©, D√©lai estim√©, Famille Produit, Cat√©gorie, Sous-cat√©gorie\n")
            f.write("- Segment, March√©, anciennete_annees, PNB cumul√© (dernier semestre)\n")
            f.write("- Taux de fond√©e calcul√©s sur 2024 (statistiquement renforc√©s)\n")
            f.write("- Ratios, interactions, log transformations (incluant PNB)\n\n")

            info = self.preprocessor.get_feature_info()
            f.write(f"NOMBRE TOTAL DE FEATURES: {info['n_features']}\n\n")

            f.write("STATISTIQUES ROBUSTES (>= 30 cas):\n")
            f.write(f"- Familles avec taux fond√©e: {info['family_stats_count']}\n")
            f.write(f"- Cat√©gories avec taux fond√©e: {info['category_stats_count']}\n")
            f.write(f"- Sous-cat√©gories avec taux fond√©e: {info['subcategory_stats_count']}\n")
            f.write(f"- Segments avec taux fond√©e: {info['segment_stats_count']}\n\n")

            # XGBoost
            f.write("="*80 + "\n")
            f.write("R√âSULTATS XGBoost\n")
            f.write("="*80 + "\n\n")

            r = self.results['XGBoost']
            f.write(f"Seuils optimaux:\n")
            f.write(f"  Seuil BAS (Rejet)      : {r['threshold_low']:.4f}\n")
            f.write(f"  Seuil HAUT (Validation): {r['threshold_high']:.4f}\n\n")

            f.write(f"M√©triques:\n")
            f.write(f"  Accuracy  : {r['accuracy']:.4f}\n")
            f.write(f"  Precision : {r['precision']:.4f}\n")
            f.write(f"  Recall    : {r['recall']:.4f}\n")
            f.write(f"  F1-Score  : {r['f1']:.4f}\n")
            f.write(f"  ROC-AUC   : {r['auc']:.4f}\n\n")

            f.write(f"Performance financi√®re:\n")
            f.write(f"  Gain NET  : {r['gain_net']:,.0f} DH\n")
            f.write(f"  Cas auto  : {r['auto']} ({r['auto']/len(self.y_test):.1%})\n\n")

            # CatBoost (si disponible)
            if 'CatBoost' in self.results:
                f.write("="*80 + "\n")
                f.write("R√âSULTATS CatBoost\n")
                f.write("="*80 + "\n\n")

                r = self.results['CatBoost']
                f.write(f"Seuils optimaux:\n")
                f.write(f"  Seuil BAS (Rejet)      : {r['threshold_low']:.4f}\n")
                f.write(f"  Seuil HAUT (Validation): {r['threshold_high']:.4f}\n\n")

                f.write(f"M√©triques:\n")
                f.write(f"  Accuracy  : {r['accuracy']:.4f}\n")
                f.write(f"  Precision : {r['precision']:.4f}\n")
                f.write(f"  Recall    : {r['recall']:.4f}\n")
                f.write(f"  F1-Score  : {r['f1']:.4f}\n")
                f.write(f"  ROC-AUC   : {r['auc']:.4f}\n\n")

                f.write(f"Performance financi√®re:\n")
                f.write(f"  Gain NET  : {r['gain_net']:,.0f} DH\n")
                f.write(f"  Cas auto  : {r['auto']} ({r['auto']/len(self.y_test):.1%})\n\n")

            # Meilleur mod√®le
            f.write("="*80 + "\n")
            f.write(f"üèÜ MEILLEUR MOD√àLE: {best_model_name}\n")
            f.write("="*80 + "\n")
            f.write(f"Crit√®re: Gain NET maximal\n")
            f.write(f"Gain NET: {self.results[best_model_name]['gain_net']:,.0f} DH\n\n")

        print(f"   ‚úÖ Rapport sauvegard√©: {report_path}")

    def run(self):
        """Ex√©cution compl√®te"""
        self.load_data()
        self.prepare_data()
        self.train_models()
        self.evaluate_models()

        # Sauvegarder
        self.save_models()
        self.save_predictions()
        self.generate_report()

        # D√©terminer le meilleur mod√®le
        best_model_name = max(self.results.items(), key=lambda x: x[1]['gain_net'])[0]

        print("\n" + "="*80)
        print("‚úÖ COMPARAISON MOD√àLES V2 TERMIN√âE")
        print("="*80)
        print(f"\nüìä R√âSULTATS COMPARATIFS:")

        print(f"\nüîπ XGBoost:")
        print(f"   F1-Score: {self.results['XGBoost']['f1']:.4f}")
        print(f"   Gain NET: {self.results['XGBoost']['gain_net']:,.0f} DH")
        print(f"   Automatisation: {self.results['XGBoost']['auto']/len(self.y_test):.1%}")
        print(f"   Seuils: [{self.results['XGBoost']['threshold_low']:.4f}, {self.results['XGBoost']['threshold_high']:.4f}]")

        if 'CatBoost' in self.results:
            print(f"\nüîπ CatBoost:")
            print(f"   F1-Score: {self.results['CatBoost']['f1']:.4f}")
            print(f"   Gain NET: {self.results['CatBoost']['gain_net']:,.0f} DH")
            print(f"   Automatisation: {self.results['CatBoost']['auto']/len(self.y_test):.1%}")
            print(f"   Seuils: [{self.results['CatBoost']['threshold_low']:.4f}, {self.results['CatBoost']['threshold_high']:.4f}]")

        print(f"\nüèÜ MEILLEUR MOD√àLE: {best_model_name}")
        print(f"   Gain NET: {self.results[best_model_name]['gain_net']:,.0f} DH")

        print(f"\nüìÇ R√©sultats: outputs/production_v2/")


if __name__ == '__main__':
    comparison = ModelComparisonV2(min_samples_stats=30)
    comparison.run()
