# Comparaison ML Pipeline V1 vs V2

## ğŸ¯ Vue d'ensemble

Deux versions du pipeline ML pour la classification des rÃ©clamations:

| Aspect | V1 (`ml_pipeline`) | V2 (`ml_pipeline_v2`) â­ |
|--------|-------------------|------------------------|
| **Objectif** | Exploration maximale | Production-ready |
| **Features** | Toutes colonnes disponibles | Uniquement colonnes temps rÃ©el |
| **Robustesse** | Stats recalculÃ©es | Stats figÃ©es (2024) |
| **ComplexitÃ©** | ~50-80 features | ~20-30 features |
| **Utilisation** | Recherche, analyse | Production, infÃ©rence |

## ğŸ“Š DiffÃ©rences dÃ©taillÃ©es

### 1. Features utilisÃ©es

#### V1 - Approche exploratoire
```python
Colonnes utilisÃ©es:
âœ“ Montant demandÃ©
âœ“ PNB analytique (vision commerciale) cumulÃ©  â† Peut ne pas Ãªtre disponible en temps rÃ©el
âœ“ Famille Produit
âœ“ CatÃ©gorie
âœ“ Sous-catÃ©gorie
âœ“ Segment
âœ“ MarchÃ©
âœ“ anciennete_annees
âœ“ Toutes autres colonnes numÃ©riques
âœ— Colonnes "Unnamed"  â† ProblÃ©matique
```

#### V2 - Approche production â­
```python
Colonnes utilisÃ©es (uniquement disponibles en production):
âœ“ Montant demandÃ©
âœ“ DÃ©lai estimÃ©
âœ“ Famille Produit
âœ“ CatÃ©gorie
âœ“ Sous-catÃ©gorie
âœ“ Segment
âœ“ MarchÃ©
âœ“ anciennete_annees

Features calculÃ©es:
âœ“ Taux de fondÃ©e par famille (calculÃ© sur 2024, robuste)
âœ“ Taux de fondÃ©e par catÃ©gorie (calculÃ© sur 2024)
âœ“ Taux de fondÃ©e par sous-catÃ©gorie (calculÃ© sur 2024)
âœ“ Ã‰cart Ã  la mÃ©diane famille
âœ“ Ratios, logs, interactions
```

### 2. Robustesse statistique

#### V1
- FrÃ©quences calculÃ©es sur toutes les donnÃ©es
- Pas de seuil minimum de cas
- Statistiques non figÃ©es

#### V2 â­
```python
RÃˆGLE: Minimum 30 cas pour calculer un taux de fondÃ©e

Exemple:
  Famille "CrÃ©dit Auto": 150 cas en 2024
    â†’ Taux fondÃ©e = 45% âœ“ (utilisÃ©)

  Famille "Assurance Vie": 12 cas en 2024
    â†’ Taux fondÃ©e = 80% âœ— (non utilisÃ©, trop peu de cas)
    â†’ Utilise taux global = 42% (fallback)

Avantage: Ã‰vite le surapprentissage sur catÃ©gories rares
```

### 3. Gestion des statistiques

#### V1
```python
# Ã€ chaque infÃ©rence, recalcule les frÃ©quences
for col in categorical_cols:
    X[f'{col}_freq'] = X[col].map(
        X[col].value_counts().to_dict()  # â† RecalculÃ©
    )
```

**ProblÃ¨me:** Les statistiques changent entre train et test !

#### V2 â­
```python
# Fit (sur 2024):
self.family_stats = {
    'taux': family_grouped['taux_fondee'].to_dict(),  # â† SauvegardÃ©
    'count': family_grouped['count'].to_dict(),
    'taux_global': 0.42
}

# Transform (sur 2025 ou production):
df['taux_fondee_famille'] = df['Famille Produit'].map(
    self.family_stats['taux']  # â† RÃ©utilisÃ© (figÃ©)
).fillna(self.family_stats['taux_global'])
```

**Avantage:** Statistiques figÃ©es, pas de data leakage

### 4. Features calculÃ©es

#### V1
```python
Features:
- ratio_pnb_montant  â† PNB peut ne pas Ãªtre disponible
- ecart_mediane_famille
- log_montant
- log_pnb  â† PNB peut ne pas Ãªtre disponible
- log_anciennete
- montant_x_anciennete
- pnb_x_anciennete  â† PNB peut ne pas Ãªtre disponible
```

#### V2 â­
```python
Features (toutes disponibles en production):
- taux_fondee_famille â­ (nouveau)
- taux_fondee_categorie â­ (nouveau)
- taux_fondee_souscategorie â­ (nouveau)
- taux_fondee_segment â­ (nouveau)
- count_famille â­ (nouveau - robustesse)
- ecart_mediane_famille
- ratio_montant_delai
- log_montant
- log_delai
- log_anciennete
- montant_x_anciennete
- delai_x_anciennete
- montant_x_delai
- montant_x_taux_famille â­ (interaction)
```

### 5. Nombre de features

| MÃ©trique | V1 | V2 |
|----------|----|----|
| Features de base | ~8-10 | 8 |
| Features calculÃ©es | ~40-70 | ~15-25 |
| **Total** | **~50-80** | **~20-30** |
| ComplexitÃ© | Ã‰levÃ©e | ModÃ©rÃ©e |

**V2 = Plus simple, plus robuste, plus interprÃ©table**

## ğŸš€ Quand utiliser quelle version ?

### Utilisez V1 si:
- âœ… Vous faites de la **recherche exploratoire**
- âœ… Vous voulez **tester toutes les features** possibles
- âœ… Vous avez **accÃ¨s Ã  toutes les colonnes** en production
- âœ… Vous voulez comparer **3 modÃ¨les** (XGBoost, RF, CatBoost)
- âœ… Vous Ãªtes en phase d'**analyse** et d'**expÃ©rimentation**

### Utilisez V2 si: â­ (RECOMMANDÃ‰ POUR PRODUCTION)
- âœ… Vous dÃ©ployez en **production**
- âœ… Vous avez des **contraintes temps rÃ©el**
- âœ… Vous voulez un modÃ¨le **simple et robuste**
- âœ… Vous voulez Ã©viter le **data leakage**
- âœ… Vous avez besoin de **statistiques figÃ©es**
- âœ… Vous voulez un modÃ¨le **interprÃ©table**

## ğŸ“ˆ Performances comparÃ©es

### MÃ©triques attendues (Ã  vÃ©rifier aprÃ¨s entraÃ®nement)

| MÃ©trique | V1 | V2 | Commentaire |
|----------|----|----|-------------|
| F1-Score | ~0.995 | ~0.993-0.995 | V2 lÃ©gÃ¨rement moins, mais plus robuste |
| Accuracy | ~0.996 | ~0.994-0.996 | TrÃ¨s similaire |
| ROC-AUC | ~0.999 | ~0.998-0.999 | Excellente dans les deux cas |
| Taux automatisation | 85-90% | 85-90% | Similaire |
| Gain NET | Ã‰levÃ© | Similaire ou meilleur | DÃ©pend des seuils |
| **Production-ready** | âŒ | âœ… | **V2 gagnant** |
| **Robustesse** | âš ï¸ | âœ… | **V2 gagnant** |
| **SimplicitÃ©** | âŒ | âœ… | **V2 gagnant** |

## ğŸ”§ Migration V1 â†’ V2

Si vous utilisez actuellement V1 et voulez migrer vers V2:

### Ã‰tape 1: VÃ©rifier les colonnes disponibles
```python
# VÃ©rifiez que vous avez ces colonnes en production:
required_columns = [
    'Montant demandÃ©',
    'DÃ©lai estimÃ©',
    'Famille Produit',
    'CatÃ©gorie',
    'Sous-catÃ©gorie',
    'Segment',
    'MarchÃ©',
    'anciennete_annees'
]
```

### Ã‰tape 2: EntraÃ®ner le modÃ¨le V2
```bash
cd ml_pipeline_v2
python model_comparison_v2.py
```

### Ã‰tape 3: Comparer les performances
```bash
# Comparer rapport V1 et V2
diff outputs/production/rapport_comparison.txt \
     outputs/production_v2/rapport_v2.txt
```

### Ã‰tape 4: Tester l'infÃ©rence
```bash
# Tester sur donnÃ©es 2025
python ml_pipeline_v2/inference_v2.py \
  --input_file data/raw/reclamations_2025.xlsx \
  --output_file test_v2.xlsx
```

### Ã‰tape 5: Valider et dÃ©ployer
- âœ… VÃ©rifier que les performances sont acceptables
- âœ… Tester sur quelques cas rÃ©els
- âœ… DÃ©ployer le modÃ¨le V2 en production
- âœ… Monitorer les performances

## ğŸ’¡ Recommandations

### Pour la recherche et l'analyse
```
Utilisez V1 (ml_pipeline)
â†’ Exploration maximale des features
â†’ Comparaison de modÃ¨les
â†’ Analyse d'interprÃ©tabilitÃ©
```

### Pour la production
```
Utilisez V2 (ml_pipeline_v2) â­
â†’ Features disponibles en temps rÃ©el
â†’ Statistiques robustes et figÃ©es
â†’ ModÃ¨le simple et performant
â†’ Pas de data leakage
```

### Workflow idÃ©al
```
1. Exploration avec V1
   â”œâ”€ Identifier les features importantes
   â”œâ”€ Comprendre les patterns
   â””â”€ Tester diffÃ©rents modÃ¨les

2. Production avec V2
   â”œâ”€ Features production-ready uniquement
   â”œâ”€ Statistiques robustes (â‰¥30 cas)
   â”œâ”€ ModÃ¨le CatBoost optimisÃ©
   â””â”€ InfÃ©rence temps rÃ©el
```

## ğŸ“š Documentation

### V1
- `ml_pipeline/README_ANALYSE.md` - Guide d'analyse
- `ml_pipeline/model_comparison.py` - Comparaison de modÃ¨les
- `ml_pipeline/analyze_results.py` - Analyse XGBoost
- `ml_pipeline/analyze_results_catboost.py` - Analyse CatBoost
- `ml_pipeline/model_interpretability.py` - InterprÃ©tabilitÃ©

### V2 â­
- `ml_pipeline_v2/README_V2.md` - Documentation complÃ¨te
- `ml_pipeline_v2/preprocessor_v2.py` - Preprocessing robuste
- `ml_pipeline_v2/model_comparison_v2.py` - EntraÃ®nement
- `ml_pipeline_v2/inference_v2.py` - InfÃ©rence production

## ğŸ“ RÃ©sumÃ©

| CritÃ¨re | V1 | V2 |
|---------|----|----|
| **ComplexitÃ©** | ğŸ”´ Ã‰levÃ©e | ğŸŸ¢ ModÃ©rÃ©e |
| **Robustesse** | ğŸŸ¡ Moyenne | ğŸŸ¢ Ã‰levÃ©e |
| **Production** | ğŸ”´ Non | ğŸŸ¢ Oui |
| **Performance** | ğŸŸ¢ Excellente | ğŸŸ¢ Excellente |
| **InterprÃ©tabilitÃ©** | ğŸŸ¡ Moyenne | ğŸŸ¢ Ã‰levÃ©e |
| **Maintenance** | ğŸ”´ Difficile | ğŸŸ¢ Facile |

**Conclusion: V2 est recommandÃ© pour la production** â­
