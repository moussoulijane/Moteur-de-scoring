# Moteur de Scoring - Production System

SystÃ¨me de classification automatique des rÃ©clamations bancaires avec ML.

## ğŸ¯ FonctionnalitÃ©s

- **EntraÃ®nement optimisÃ©** : XGBoost et CatBoost avec optimisation Optuna
- **PrÃ©processing robuste** : Statistiques figÃ©es, features disponibles en temps rÃ©el
- **Versioning des modÃ¨les** : Gestion des versions avec mÃ©tadonnÃ©es
- **Mode Batch** : Traitement de fichiers Excel
- **Mode Temps RÃ©el** : API REST pour infÃ©rences instantanÃ©es
- **RÃ¨gles mÃ©tier** : Application automatique des rÃ¨gles d'affaires
- **DockerisÃ©** : DÃ©ploiement facile avec Docker

## ğŸ“ Structure du Projet

```
production/
â”œâ”€â”€ config/                  # Configuration
â”‚   â”œâ”€â”€ config.yaml         # Configuration principale
â”‚   â””â”€â”€ config_loader.py    # Chargeur de config
â”œâ”€â”€ src/                    # Code source
â”‚   â”œâ”€â”€ api/               # API REST
â”‚   â”œâ”€â”€ inference/         # Modules d'infÃ©rence
â”‚   â”œâ”€â”€ models/            # Gestion des modÃ¨les
â”‚   â”œâ”€â”€ preprocessing/     # PrÃ©processing
â”‚   â”œâ”€â”€ training/          # EntraÃ®nement
â”‚   â””â”€â”€ utils/             # Utilitaires
â”œâ”€â”€ models/                 # ModÃ¨les sauvegardÃ©s
â”œâ”€â”€ tests/                  # Tests unitaires
â”œâ”€â”€ logs/                   # Logs
â”œâ”€â”€ data/                   # DonnÃ©es
â”œâ”€â”€ train_model.py          # Script d'entraÃ®nement
â”œâ”€â”€ batch_inference.py      # Script batch
â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â”œâ”€â”€ Dockerfile             # Image Docker
â”œâ”€â”€ docker-compose.yml     # Orchestration Docker
â””â”€â”€ README.md              # Documentation

## ğŸš€ Installation

### Option 1: Installation locale

```bash
# Clone le projet
cd production

# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# Installer les dÃ©pendances
pip install -r requirements.txt
```

### Option 2: Docker

```bash
# Build l'image
docker-compose build

# Lancer l'API
docker-compose up api
```

## ğŸ“Š EntraÃ®nement du ModÃ¨le

### 1. PrÃ©parer les donnÃ©es

Les donnÃ©es doivent Ãªtre au format Excel avec les colonnes requises :
- `Montant demandÃ©`
- `Famille Produit`
- `Fondee` (pour l'entraÃ®nement uniquement)

Colonnes optionnelles (recommandÃ©es) :
- `DÃ©lai estimÃ©`
- `CatÃ©gorie`, `Sous-catÃ©gorie`
- `Segment`, `MarchÃ©`
- `anciennete_annees`
- `PNB analytique (vision commerciale) cumulÃ©`

### 2. Lancer l'entraÃ®nement

```bash
python train_model.py \
    --train ../data/raw/reclamations_2024.xlsx \
    --test ../data/raw/reclamations_2025.xlsx \
    --output models/
```

Le systÃ¨me va :
1. Charger et prÃ©parer les donnÃ©es
2. Optimiser les hyperparamÃ¨tres (Optuna)
3. EntraÃ®ner XGBoost et CatBoost
4. Optimiser les seuils de dÃ©cision
5. Ã‰valuer sur les donnÃ©es de test
6. Sauvegarder les modÃ¨les et mÃ©tadonnÃ©es

### 3. RÃ©sultats

Les modÃ¨les entraÃ®nÃ©s seront sauvegardÃ©s dans `models/` :
- `best_model.pkl` : Meilleur modÃ¨le
- `xgboost_model.pkl` : ModÃ¨le XGBoost
- `catboost_model.pkl` : ModÃ¨le CatBoost
- `preprocessor.pkl` : PrÃ©processeur
- `thresholds.pkl` : Seuils optimisÃ©s
- `model_info.txt` : Informations du modÃ¨le

## ğŸ”® InfÃ©rence

### Mode 1: Batch (Fichiers Excel)

Pour traiter un fichier Excel complet :

```bash
python batch_inference.py \
    --input data/nouvelles_reclamations.xlsx \
    --output results/predictions.xlsx \
    --model best \
    --apply-rules
```

**Arguments** :
- `--input` : Fichier Excel d'entrÃ©e
- `--output` : Fichier Excel de sortie (optionnel, auto-gÃ©nÃ©rÃ© si omis)
- `--model` : ModÃ¨le Ã  utiliser (`best`, `xgboost`, `catboost`)
- `--apply-rules` : Appliquer les rÃ¨gles mÃ©tier
- `--version` : Version du modÃ¨le (optionnel)

**Sortie** :
Le fichier Excel contiendra les colonnes originales plus :
- `Probabilite_Fondee` : ProbabilitÃ© prÃ©dite [0-1]
- `Decision_Modele` : Rejet Auto / Audit Humain / Validation Auto
- `Decision_Code` : -1 (Rejet) / 0 (Audit) / 1 (Validation)
- `Raison_Audit` : Raison de l'audit (si rÃ¨gles appliquÃ©es)

### Mode 2: Temps RÃ©el (API REST)

#### DÃ©marrer l'API

```bash
# Locale
python src/api/app.py

# Ou avec Docker
docker-compose up api
```

L'API sera accessible sur `http://localhost:5000`

#### Endpoints

**1. Health Check**

```bash
curl http://localhost:5000/health
```

**2. PrÃ©diction Unique**

```bash
curl -X POST http://localhost:5000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "Montant demandÃ©": 5000,
    "Famille Produit": "Cartes",
    "DÃ©lai estimÃ©": 30,
    "CatÃ©gorie": "DÃ©bit non autorisÃ©",
    "Segment": "Particuliers",
    "anciennete_annees": 5,
    "PNB analytique (vision commerciale) cumulÃ©": 15000
  }'
```

**RÃ©ponse** :
```json
{
  "prediction": {
    "Probabilite_Fondee": 0.75,
    "Decision_Modele": "Validation Auto",
    "Decision_Code": 1
  },
  "timestamp": "2024-01-15T10:30:00"
}
```

**3. PrÃ©diction Batch (petits lots)**

```bash
curl -X POST http://localhost:5000/predict/batch \
  -H "Content-Type: application/json" \
  -d '{
    "complaints": [
      {"Montant demandÃ©": 5000, "Famille Produit": "Cartes", ...},
      {"Montant demandÃ©": 3000, "Famille Produit": "Comptes", ...}
    ]
  }'
```

**RÃ©ponse** :
```json
{
  "predictions": [...],
  "summary": {
    "total": 2,
    "Rejet Auto": 0,
    "Audit Humain": 0,
    "Validation Auto": 2
  },
  "timestamp": "2024-01-15T10:30:00"
}
```

**4. Informations du ModÃ¨le**

```bash
curl http://localhost:5000/model/info
```

## âš™ï¸ Configuration

La configuration se trouve dans `config/config.yaml`.

Sections principales :
- `data` : Fichiers de donnÃ©es
- `preprocessing` : ParamÃ¨tres de prÃ©processing
- `models` : Configuration des modÃ¨les
- `thresholds` : Seuils de dÃ©cision
- `business_rules` : RÃ¨gles mÃ©tier
- `api` : Configuration de l'API

Exemple de modification :

```yaml
business_rules:
  max_validations_per_client_per_year: 2  # Au lieu de 1
  check_amount_vs_pnb: true

api:
  host: "0.0.0.0"
  port: 8080  # Au lieu de 5000
```

## ğŸ§ª Tests

Lancer les tests :

```bash
pytest tests/ -v
```

Avec couverture :

```bash
pytest tests/ --cov=src --cov-report=html
```

## ğŸ³ DÃ©ploiement Docker

### API seulement

```bash
docker-compose up -d api
```

### Avec entraÃ®nement

```bash
# Build
docker-compose build

# EntraÃ®ner le modÃ¨le
docker-compose --profile training up training

# Lancer l'API
docker-compose up -d api
```

## ğŸ“ˆ SystÃ¨me de DÃ©cision (3 Zones)

Le systÃ¨me utilise 2 seuils pour crÃ©er 3 zones :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ProbabilitÃ© â‰¤ seuil_bas                        â”‚
â”‚  â†’ REJET AUTOMATIQUE (code: -1)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  seuil_bas < ProbabilitÃ© < seuil_haut           â”‚
â”‚  â†’ AUDIT HUMAIN (code: 0)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ProbabilitÃ© â‰¥ seuil_haut                       â”‚
â”‚  â†’ VALIDATION AUTOMATIQUE (code: 1)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Les seuils sont optimisÃ©s automatiquement lors de l'entraÃ®nement pour maximiser :
- Le gain financier net
- Le taux d'automatisation
- La prÃ©cision des dÃ©cisions

## ğŸ“‹ RÃ¨gles MÃ©tier

**RÃ¨gle #1** : Maximum 1 validation automatique par client par annÃ©e
- La premiÃ¨re validation de l'annÃ©e est autorisÃ©e
- Les suivantes sont envoyÃ©es en audit humain

**RÃ¨gle #2** : Montant validÃ© â‰¤ PNB de l'annÃ©e derniÃ¨re
- Si montant > PNB cumulÃ© â†’ audit humain
- ProtÃ¨ge contre les validations de montants anormalement Ã©levÃ©s

Ces rÃ¨gles s'appliquent automatiquement avec `--apply-rules` (batch) ou `?apply_rules=true` (API).

## ğŸ”„ Versioning des ModÃ¨les

Les modÃ¨les sont versionnÃ©s automatiquement :

```python
from src.inference import ModelManager

manager = ModelManager('models/')

# Lister les versions
versions = manager.list_versions()

# Charger une version spÃ©cifique
model, prep, thresh = manager.load_model(
    model_name='best',
    version='v_20240115_103000'
)

# Info sur une version
info = manager.get_version_info('v_20240115_103000')
```

## ğŸ“Š Monitoring et Logs

Les logs sont sauvegardÃ©s dans `logs/app.log` avec rotation automatique.

Niveau de log configurable dans `config.yaml` :

```yaml
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
```

## ğŸ› ï¸ DÃ©veloppement

### Structure du Code

- **Modulaire** : Chaque composant est indÃ©pendant
- **TypÃ©** : Utilisation de type hints
- **DocumentÃ©** : Docstrings complÃ¨tes
- **TestÃ©** : Tests unitaires et d'intÃ©gration

### Ajouter un Nouveau ModÃ¨le

1. CrÃ©er une mÃ©thode dans `src/training/trainer.py` :

```python
def _optimize_lightgbm(self, n_trials: int = 50):
    # ImplÃ©mentation
    pass
```

2. Ajouter dans `train_models()` :

```python
if 'lightgbm' in algorithms:
    self.models['lightgbm'] = self._optimize_lightgbm(n_trials)
```

3. Mettre Ã  jour la config :

```yaml
models:
  algorithms:
    - xgboost
    - catboost
    - lightgbm
```

## ğŸ¤ Support

Pour toute question ou problÃ¨me :
1. VÃ©rifier les logs dans `logs/`
2. Consulter la configuration dans `config/config.yaml`
3. Lancer les tests : `pytest tests/ -v`

## ğŸ“ License

PropriÃ©taire - Tous droits rÃ©servÃ©s
